{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ee3ebdd-9338-4da0-8221-ec18150520ea",
   "metadata": {},
   "source": [
    "# Necessary imports for recipes generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4091df13-f54c-4147-8bcc-da9550bbdd35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /home/dagus/venv/lib/python3.11/site-packages (3.8.1)\n",
      "Requirement already satisfied: click in /home/dagus/venv/lib/python3.11/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /home/dagus/venv/lib/python3.11/site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/dagus/venv/lib/python3.11/site-packages (from nltk) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in /home/dagus/venv/lib/python3.11/site-packages (from nltk) (4.66.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/keras-team/keras-nlp.git -q\n",
    "!pip install -q tensorflow-text\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0289132-124f-47bb-bc27-4dd11cb96054",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-05 16:29:46.127130: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-05 16:29:46.154110: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-05 16:29:46.554774: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"jax\"  # \"jax\" or \"tensorflow\" or \"torch\"\n",
    "import numpy as np\n",
    "import keras_nlp\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_text as tf_text\n",
    "from tensorflow import keras\n",
    "from tensorflow.lite.python import interpreter\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36e4ccc-ec4b-406e-b058-337d259e2531",
   "metadata": {},
   "source": [
    "# Dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18eccacb-136b-42ad-a421-1591a846eb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_attr_not_empty(attr: str):\n",
    "    return pd.notna(attr) and attr.strip() != \"NA\" and attr.strip() != \"N/A\" and attr.strip().lower() != \"nan\" and not attr.isspace()\n",
    "def load_preprocess_raw_csv_data(file, max_chars=1500):\n",
    "    '''\n",
    "        This method is aimed at preprocessing recipes\n",
    "        from the following dataset:\n",
    "        https://www.kaggle.com/datasets/irkaal/foodcom-recipes-and-reviews\n",
    "        take raw recipe data and preprocess it,\n",
    "        return a list of recipe instances\n",
    "\n",
    "        parameter: raw data\n",
    "\n",
    "        return: recipe instance list\n",
    "    '''\n",
    "    recipes = []\n",
    "    df = pd.read_csv(file, dtype=str)\n",
    "    for index, row in df.iterrows():\n",
    "        title = row['Name']\n",
    "        quantities = row['RecipeIngredientQuantities'][2:-1].split(\",\") if pd.notna(row[\"RecipeIngredientQuantities\"]) else row[\"RecipeIngredientQuantities\"]\n",
    "        if isinstance(row['RecipeIngredientParts'], str) and is_attr_not_empty(row['RecipeIngredientParts']):\n",
    "            ingredient_classes = row['RecipeIngredientParts'][2:-1]\n",
    "        else:\n",
    "            continue\n",
    "        ingredients = ingredient_classes.split(\",\")\n",
    "        if isinstance(row['RecipeInstructions'], str) and is_attr_not_empty(row['RecipeInstructions']):\n",
    "            instructions = row['RecipeInstructions'][2:-1].split(\",\")\n",
    "        else:\n",
    "            continue\n",
    "        instructions = \"\".join(instructions)\n",
    "        ingredients_list = \"\"\n",
    "        if not isinstance(ingredients, list):\n",
    "            ingredients = [ingredients]\n",
    "        if not isinstance(quantities, list):\n",
    "            quantities = [quantities]\n",
    "        n_ingre = min(len(quantities), len(ingredients))\n",
    "        for i in range(n_ingre):\n",
    "            #if not is_attr_not_empty(ingredients[i]):\n",
    "            #    continue\n",
    "            if not is_attr_not_empty(quantities[i]) and is_attr_not_empty(ingredients[i]):\n",
    "                ingredients_list += ingredients[i]\n",
    "            else:\n",
    "                ingredients_list += str(quantities[i]) + \" \" + ingredients[i].strip()\n",
    "\n",
    "            if i != n_ingre - 1:\n",
    "                ingredients_list += \", \"\n",
    "\n",
    "        servings = row['RecipeServings'] if is_attr_not_empty(str(row['RecipeServings'])) else 1\n",
    "        cook_time = row['CookTime'] if is_attr_not_empty(str(row['CookTime'])) else \"PT0M\"\n",
    "        preparation_time = row['PrepTime'] if is_attr_not_empty(str(row['PrepTime'])) else \"PT0M\"\n",
    "        total_time = row['TotalTime'] if is_attr_not_empty(str(row['TotalTime'])) else \"PT0M\"\n",
    "\n",
    "        ingredient_classes = ingredient_classes.replace('\"', \"\")\n",
    "        title = title.replace('\"', \"\")\n",
    "        ingredients_list = ingredients_list.replace('\"', \"\")\n",
    "        instructions = instructions.replace('\"', \"\")\n",
    "\n",
    "        ingredient_classes = ingredient_classes.replace(\"\\\\\", \"\")\n",
    "        title = title.replace(\"\\\\\", \"\")\n",
    "        ingredients_list = ingredients_list.replace(\"\\\\\", \"\")\n",
    "        instructions = instructions.replace(\"\\\\\", \"\")\n",
    "\n",
    "        recipe_instance = f\"[START]Prompt: {html.unescape(ingredient_classes.strip())}\" \\\n",
    "                f\"\\nTitle: {html.unescape(title)}\" \\\n",
    "                f\"\\nIngredients: {html.unescape(ingredients_list.strip())}\" \\\n",
    "                f\"\\nServings: {str(servings)}\" \\\n",
    "                f\"\\nInstructions: {html.unescape(instructions.strip())}\" \\\n",
    "                f\"\\nCook time: {html.unescape(str(cook_time))}\" \\\n",
    "                f\"\\nPreparation time: {html.unescape(str(preparation_time))}\" \\\n",
    "                f\"\\nTotal time: {html.unescape(str(total_time))}[END]\"\n",
    "        if len(recipe_instance) <= max_chars:\n",
    "            recipes.append(recipe_instance)\n",
    "    return recipes\n",
    "\n",
    "def load_preprocess_raw_json_data(raw_data, max_chars=1500):\n",
    "    '''\n",
    "    This method is aimed at preprocessing recipes\n",
    "    from the following dataset: https://eightportions.com/datasets/Recipes/\n",
    "    take raw recipe data and preprocess it,\n",
    "    return a list of recipe instances\n",
    "\n",
    "    parameter: raw data\n",
    "\n",
    "    return: recipe instance list\n",
    "\n",
    "    '''\n",
    "    with open(raw_data, 'r') as f:\n",
    "        raw_dict = json.load(f)\n",
    "    f.close()\n",
    "\n",
    "    raw_list = []\n",
    "    for recipe in raw_dict.values():\n",
    "        # try/except will filter out recipes that don't have title, ingredients or instructions\n",
    "        try:\n",
    "            title = recipe['title'].replace(\"ADVERTISEMENT\", \"\")\n",
    "            ingredient_list = recipe['ingredients']\n",
    "            ingredients = \"\"\n",
    "            ingredient_classes = \"\"\n",
    "            for ingredient in ingredient_list:\n",
    "                ingredient = ingredient.replace(\"ADVERTISEMENT\", \"\")\n",
    "                if ingredient != \"\":\n",
    "                    ingredients += ingredient + \", \"\n",
    "                    ingredient = ingredient.split('/')[0].strip()\n",
    "                    ingredient = ingredient.split(')')\n",
    "                    if len(ingredient) == 1:\n",
    "                        ingredient = ingredient[0].strip()\n",
    "                    else:\n",
    "                        ingredient = ingredient[1].strip()\n",
    "                    # Use re.sub() to replace the number with an empty string\n",
    "                    ingredient = re.sub(r'\\d+', '', ingredient).strip()\n",
    "\n",
    "                    if ingredient != \"\":\n",
    "                        ingredient_classes += ingredient + \", \"\n",
    "\n",
    "            instructions = recipe['instructions'].replace(\"ADVERTISEMENT\", \"\")\n",
    "            recipe_instance = f\"[START]Prompt: {ingredient_classes.strip()}\" \\\n",
    "                              f\"Title: {title.strip()}\" \\\n",
    "                              f\"Ingredients: {ingredient.strip()}\" \\\n",
    "                              f\"Instructions: {instructions.strip()}[END]\"\n",
    "            if len(recipe_instance) <= max_chars:\n",
    "                raw_list.append(recipe_instance)\n",
    "\n",
    "        except:\n",
    "            continue\n",
    "    return raw_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f11d1a42-dee8-4960-a76a-4e8ee23880d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recipes_generator.data.recipe_dataset import load_preprocess_raw_json_data, load_preprocess_raw_csv_data\n",
    "recipes1 = load_preprocess_raw_json_data('recipes_generator/data/recipes_raw_nosource_ar.json')\n",
    "recipes2 = load_preprocess_raw_json_data('recipes_generator/data/recipes_raw_nosource_epi.json')\n",
    "recipes3 = load_preprocess_raw_json_data('recipes_generator/data/recipes_raw_nosource_fn.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62d066f3-843a-4706-a59d-cda4e6d78a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes4 = load_preprocess_raw_csv_data('recipes_generator/data/recipes_general.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5be71112-9716-49a9-b319-ed2a637634b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_list = recipes1 + recipes2 + recipes3 + recipes4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84720437-7c4e-4cd3-b45c-4f0b2c1d0972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39441\n",
      "18152\n",
      "55791\n",
      "502883\n"
     ]
    }
   ],
   "source": [
    "print(len(recipes1))\n",
    "print(len(recipes2))\n",
    "print(len(recipes3))\n",
    "print(len(recipes4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0557a17f-6925-4914-a32e-b7b648d20e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train data:  443711\n",
      "Number of test data:  1021\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "#train_list, test_list = np.split(recipe_list, [int(.8*len(recipe_list))])\n",
    "random.shuffle(recipe_list)\n",
    "train_list, test_list = recipe_list[:int(.8*len(recipe_list))], recipe_list[int(.8*len(recipe_list))]\n",
    "train_list, val_list = train_list[:int(.9*len(train_list))], recipe_list[int(.9*len(train_list))]\n",
    "print('Number of train data: ', len(train_list))\n",
    "print('Number of test data: ', len(test_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f879b83e-33a4-4c99-8f59-6194124a8c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2', bos_token='<|startoftext|>', eos_token='<|endoftext|>', pad_token='<|pad|>')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e45e66-c618-4dd8-9e62-e6dbcbdfb7bd",
   "metadata": {},
   "source": [
    "# Model import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7df273bf-2526-43ec-8279-cc79710a569d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-05 16:30:11.094573: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-05 16:30:11.099308: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-05 16:30:11.102654: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-05 16:30:11.107085: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-05 16:30:11.110411: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-05 16:30:11.113634: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-05 16:30:11.232900: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-05 16:30:11.234150: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-05 16:30:11.235236: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2024-05-05 16:30:11.235267: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-05 16:30:11.236479: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10168 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "Downloading from https://www.kaggle.com/api/v1/models/keras/gpt2/keras/gpt2_base_en/2/download/preprocessor.json...\n",
      "Downloading from https://www.kaggle.com/api/v1/models/keras/gpt2/keras/gpt2_base_en/2/download/task.json...\n"
     ]
    }
   ],
   "source": [
    "gpt2_tokenizer = keras_nlp.models.GPT2Tokenizer.from_preset(\"gpt2_base_en\")\n",
    "gpt2_preprocessor = keras_nlp.models.GPT2CausalLMPreprocessor.from_preset(\n",
    "        \"gpt2_base_en\",\n",
    "        sequence_length=256,\n",
    "        add_end_token=True,\n",
    ")\n",
    "gpt2_lm = keras_nlp.models.GPT2CausalLM.from_preset(\"gpt2_base_en\", preprocessor=gpt2_preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb9ac671-fbb6-4a69-bfb1-c50e3b6525b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/dagus/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import tokenize\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fef9f02e-1b0d-442a-b1ee-064d23f4d270",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                             | 45.0/443711 [01:38<270:52:00,  2.20s/it]\n",
      "  0%|                                                                                                                                                                                             | 6.0/443711 [01:17<1498:48:10, 12.16s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m bar \u001b[38;5;241m=\u001b[39m tqdm(total\u001b[38;5;241m=\u001b[39mtotal)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m recipe \u001b[38;5;129;01min\u001b[39;00m train_list:\n\u001b[0;32m----> 9\u001b[0m   rec \u001b[38;5;241m=\u001b[39m \u001b[43mgpt2_tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecipe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m   all_recipes\u001b[38;5;241m.\u001b[39mextend(rec)\n\u001b[1;32m     11\u001b[0m   count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/venv/lib/python3.11/site-packages/keras_nlp/src/tokenizers/byte_pair_tokenizer.py:570\u001b[0m, in \u001b[0;36mBytePairTokenizer.tokenize\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    566\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache\u001b[38;5;241m.\u001b[39mlookup(flat_tokens)\n\u001b[1;32m    568\u001b[0m \u001b[38;5;66;03m# If `has_unseen_words == True`, it means not all tokens are in cache,\u001b[39;00m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;66;03m# we will process the unseen tokens. Otherwise return the cache lookup.\u001b[39;00m\n\u001b[0;32m--> 570\u001b[0m tokenized_words \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcond\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    571\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_unseen_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    572\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprocess_unseen_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    573\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_lookup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    576\u001b[0m tokens \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mstrings\u001b[38;5;241m.\u001b[39msplit(tokenized_words, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_dtype \u001b[38;5;241m!=\u001b[39m tf\u001b[38;5;241m.\u001b[39mstring:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;66;03m# Encode merged tokens.\u001b[39;00m\n",
      "File \u001b[0;32m~/venv/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/venv/lib/python3.11/site-packages/tensorflow/python/util/dispatch.py:1260\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1258\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1259\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1260\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   1262\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1263\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1264\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m~/venv/lib/python3.11/site-packages/tensorflow/python/ops/cond.py:343\u001b[0m, in \u001b[0;36mcond_for_tf_v2\u001b[0;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcond\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[1;32m    244\u001b[0m \u001b[38;5;129m@dispatch\u001b[39m\u001b[38;5;241m.\u001b[39madd_dispatch_support\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcond_for_tf_v2\u001b[39m(pred, true_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, false_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    246\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Return `true_fn()` if the predicate `pred` is true else `false_fn()`.\u001b[39;00m\n\u001b[1;32m    247\u001b[0m \n\u001b[1;32m    248\u001b[0m \u001b[38;5;124;03m  Note: This op is automatically used in a `tf.function` to convert Python\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    341\u001b[0m \n\u001b[1;32m    342\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 343\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcond\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrue_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrue_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfalse_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfalse_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/venv/lib/python3.11/site-packages/tensorflow/python/util/dispatch.py:1260\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1258\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1259\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1260\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   1262\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1263\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1264\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m~/venv/lib/python3.11/site-packages/tensorflow/python/util/deprecation.py:588\u001b[0m, in \u001b[0;36mdeprecated_args.<locals>.deprecated_wrapper.<locals>.new_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    580\u001b[0m         _PRINTED_WARNING[(func, arg_name)] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    581\u001b[0m       _log_deprecation(\n\u001b[1;32m    582\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFrom \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: calling \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m (from \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) with \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is deprecated and will \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    583\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbe removed \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mInstructions for updating:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    586\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124min a future version\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m date \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m date),\n\u001b[1;32m    587\u001b[0m           instructions)\n\u001b[0;32m--> 588\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv/lib/python3.11/site-packages/tensorflow/python/ops/cond.py:142\u001b[0m, in \u001b[0;36mcond\u001b[0;34m(pred, true_fn, false_fn, strict, name, fn1, fn2)\u001b[0m\n\u001b[1;32m    139\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfalse_fn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must be callable.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 142\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_eager_cond_implementation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrue_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfalse_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;66;03m# Always enable control flow v2 if building a function, regardless of toggle.\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m util\u001b[38;5;241m.\u001b[39mEnableControlFlowV2(ops\u001b[38;5;241m.\u001b[39mget_default_graph()):\n",
      "File \u001b[0;32m~/venv/lib/python3.11/site-packages/tensorflow/python/ops/cond.py:385\u001b[0m, in \u001b[0;36m_eager_cond_implementation\u001b[0;34m(pred, true_fn, false_fn, strict, name)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mname_scope(name, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcond\u001b[39m\u001b[38;5;124m\"\u001b[39m, [pred]):\n\u001b[1;32m    384\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m pred_constant_value:\n\u001b[0;32m--> 385\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtrue_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    386\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    387\u001b[0m     result \u001b[38;5;241m=\u001b[39m false_fn()\n",
      "File \u001b[0;32m~/venv/lib/python3.11/site-packages/keras_nlp/src/tokenizers/byte_pair_tokenizer.py:565\u001b[0m, in \u001b[0;36mBytePairTokenizer.tokenize.<locals>.process_unseen_tokens\u001b[0;34m()\u001b[0m\n\u001b[1;32m    563\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_unseen_tokens\u001b[39m():\n\u001b[1;32m    564\u001b[0m     unseen_tokens \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mboolean_mask(flat_tokens, cache_mask)\n\u001b[0;32m--> 565\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bpe_merge_and_update_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43munseen_tokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    566\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache\u001b[38;5;241m.\u001b[39mlookup(flat_tokens)\n",
      "File \u001b[0;32m~/venv/lib/python3.11/site-packages/keras_nlp/src/tokenizers/byte_pair_tokenizer.py:630\u001b[0m, in \u001b[0;36mBytePairTokenizer._bpe_merge_and_update_cache\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Process unseen tokens and add to cache.\"\"\"\u001b[39;00m\n\u001b[1;32m    629\u001b[0m words \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform_bytes(tokens)\n\u001b[0;32m--> 630\u001b[0m tokenized_words \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bpe_merge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwords\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;66;03m# For each word, join all its token by a whitespace,\u001b[39;00m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;66;03m# e.g., [\"dragon\", \"fly\"] => \"dragon fly\" for hash purpose.\u001b[39;00m\n\u001b[1;32m    634\u001b[0m tokenized_words \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mstrings\u001b[38;5;241m.\u001b[39mreduce_join(\n\u001b[1;32m    635\u001b[0m     tokenized_words, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, separator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    636\u001b[0m )\n",
      "File \u001b[0;32m~/venv/lib/python3.11/site-packages/keras_nlp/src/tokenizers/byte_pair_tokenizer.py:517\u001b[0m, in \u001b[0;36mBytePairTokenizer._bpe_merge\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mreduce_any(mask)\n\u001b[1;32m    516\u001b[0m initial_mask \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mfill((num_words,), \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 517\u001b[0m merged_words, _ \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhile_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloop_condition\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bpe_merge_one_step\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloop_vars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m        \u001b[49m\u001b[43minitial_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshape_invariants\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensorShape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensorShape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m merged_words\n",
      "File \u001b[0;32m~/venv/lib/python3.11/site-packages/tensorflow/python/util/deprecation.py:660\u001b[0m, in \u001b[0;36mdeprecated_arg_values.<locals>.deprecated_wrapper.<locals>.new_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    652\u001b[0m           _PRINTED_WARNING[(func, arg_name)] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    653\u001b[0m         _log_deprecation(\n\u001b[1;32m    654\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFrom \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: calling \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m (from \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) with \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is deprecated and \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    655\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwill be removed \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mInstructions for updating:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    658\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124min a future version\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m date \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m\n\u001b[1;32m    659\u001b[0m             (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m date), instructions)\n\u001b[0;32m--> 660\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv/lib/python3.11/site-packages/tensorflow/python/ops/while_loop.py:241\u001b[0m, in \u001b[0;36mwhile_loop_v2\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, maximum_iterations, name)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhile_loop\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[1;32m     36\u001b[0m \u001b[38;5;129m@deprecation\u001b[39m\u001b[38;5;241m.\u001b[39mdeprecated_arg_values(\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     52\u001b[0m                   maximum_iterations\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     53\u001b[0m                   name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     54\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Repeat `body` while the condition `cond` is true.\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \n\u001b[1;32m     56\u001b[0m \u001b[38;5;124;03m  Note: This op is automatically used in a `tf.function` to convert Python for-\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    239\u001b[0m \n\u001b[1;32m    240\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 241\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwhile_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcond\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcond\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m      \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m      \u001b[49m\u001b[43mloop_vars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloop_vars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m      \u001b[49m\u001b[43mshape_invariants\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape_invariants\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m      \u001b[49m\u001b[43mparallel_iterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparallel_iterations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m      \u001b[49m\u001b[43mback_prop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mback_prop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m      \u001b[49m\u001b[43mswap_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswap_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmaximum_iterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximum_iterations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m      \u001b[49m\u001b[43mreturn_same_structure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv/lib/python3.11/site-packages/tensorflow/python/ops/while_loop.py:488\u001b[0m, in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m    485\u001b[0m loop_var_structure \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mmap_structure(type_spec\u001b[38;5;241m.\u001b[39mtype_spec_from_value,\n\u001b[1;32m    486\u001b[0m                                         \u001b[38;5;28mlist\u001b[39m(loop_vars))\n\u001b[1;32m    487\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m cond(\u001b[38;5;241m*\u001b[39mloop_vars):\n\u001b[0;32m--> 488\u001b[0m   loop_vars \u001b[38;5;241m=\u001b[39m \u001b[43mbody\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mloop_vars\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    489\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m try_to_pack \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(loop_vars, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m    490\u001b[0m     packed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/venv/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/venv/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1503\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1504\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1505\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1506\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1515\u001b[0m   )\n",
      "File \u001b[0;32m~/venv/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "all_recipes = []\n",
    "count = 0\n",
    "total = len(train_list)\n",
    "progressbar_update_freq = 500\n",
    "bar = tqdm(total=total)\n",
    "\n",
    "for recipe in train_list:\n",
    "  rec = gpt2_tokenizer.tokenize(recipe)\n",
    "  all_recipes.extend(rec)\n",
    "  count += 1\n",
    "  if count % progressbar_update_freq == 0:\n",
    "    bar.update(count / progressbar_update_freq)\n",
    "bar.update(total - count % progressbar_update_freq)\n",
    "bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f28681e2-9238-4ada-baf4-7dd8c79c012f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_train_ds = tf.data.Dataset.from_tensor_slices(train_list)\n",
    "processed_ds = tf_train_ds.batch(32).cache().prefetch(tf.data.AUTOTUNE)#tf_train_ds.map(gpt2_preprocessor, tf.data.AUTOTUNE).batch(32).cache().prefetch(tf.data.AUTOTUNE)\n",
    "part_of_ds = processed_ds.take(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a2d1677-d2f5-499d-afd7-f3609fcbdcf3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Layer 'gpt2_causal_lm' expected 2 input(s). Received 1 instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 15\u001b[0m\n\u001b[1;32m     10\u001b[0m loss \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mSparseCategoricalCrossentropy(from_logits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     11\u001b[0m gpt2_lm\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m     12\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(lr),\n\u001b[1;32m     13\u001b[0m     loss\u001b[38;5;241m=\u001b[39mloss,\n\u001b[1;32m     14\u001b[0m     weighted_metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 15\u001b[0m \u001b[43mgpt2_lm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m gpt2_lm\u001b[38;5;241m.\u001b[39mfit(processed_ds, epochs\u001b[38;5;241m=\u001b[39mnum_epochs)\n",
      "File \u001b[0;32m~/venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/venv/lib/python3.11/site-packages/keras/src/layers/input_spec.py:156\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    154\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tree\u001b[38;5;241m.\u001b[39mflatten(inputs)\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(input_spec) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(inputs):\n\u001b[0;32m--> 156\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLayer \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m expected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(input_spec)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m input(s). \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    158\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(inputs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    159\u001b[0m     )\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m inputs:\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;66;03m# Having a shape/dtype is the only commonality of the various\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# tensor-like objects that may be passed. The most common kind of\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# invalid type we are guarding for is a Layer instance (Functional API),\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# which does not have a `shape` attribute.\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[0;31mValueError\u001b[0m: Layer 'gpt2_causal_lm' expected 2 input(s). Received 1 instead."
     ]
    }
   ],
   "source": [
    "gpt2_lm.include_preprocessing = False\n",
    "\n",
    "num_epochs = 2\n",
    "\n",
    "lr = tf.keras.optimizers.schedules.PolynomialDecay(\n",
    "    5e-5,\n",
    "    decay_steps=part_of_ds.cardinality() * num_epochs,\n",
    "    end_learning_rate=0.0,\n",
    ")\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "gpt2_lm.compile(\n",
    "    optimizer=keras.optimizers.Adam(lr),\n",
    "    loss=loss,\n",
    "    weighted_metrics=[\"accuracy\"])\n",
    "gpt2_lm.__call__(train_list[0], train_list[1])\n",
    "gpt2_lm.fit(processed_ds, epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ddab7b-d294-498d-afe9-3d0b9d3f427d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = gpt2_lm.generate(\"Breaking news: Driver ran after accident\", max_length=200)\n",
    "print(\"\\nGPT-2 output:\")\n",
    "print(output.numpy().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad39d03-e401-41d0-b505-2b4ae5937d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2_lm.backbone.save_weights(\"finetuned_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97a60a4-ee8f-4dea-883e-7fb7e21596cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8a1298-5229-472b-8b2e-d8ca83f30645",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c141361c-a687-4632-8daf-acad11dc560d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e7bd2f-5d1b-4e39-92c5-13d2f38c51e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea351a4-5201-4c1a-a8ab-d1ee1a5c69d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6597f3-3edb-4fcf-a596-29922aa7e48a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79947fe8-a7ce-4078-b9f3-36baabe0aa27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3687d750-222f-4b54-b8a5-81e6f6d14f8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87ec745-f72c-4b06-bed0-e96856b1362a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33aeb800-6278-4e2f-b0f4-b65bb7f27abc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8803490a-8eeb-45d9-a72f-cdd3e7ab7171",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a3cdbf0-f7ed-4ccc-8999-061c9530d130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50259, 768)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('distilbert/distilgpt2', bos_token='<|startoftext|>', eos_token='<|endoftext|>', pad_token='<|pad|>')\n",
    "# I'm not really doing anything with the config buheret\n",
    "configuration = GPT2Config.from_pretrained('distilbert/distilgpt2', output_hidden_states=False)\n",
    "\n",
    "# instantiate the model\n",
    "model = GPT2LMHeadModel.from_pretrained(\"distilbert/distilgpt2\", config=configuration)\n",
    "\n",
    "# this step is necessary because I've added some tokens (bos_token, etc) to the embeddings\n",
    "# otherwise the tokenizer and model tensors won't match up\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b38a44b9-b940-4d8f-a7ce-e2bbb49fdb99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "443,711 training samples\n",
      "49,302 validation samples\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, random_split, RandomSampler, SequentialSampler\n",
    "\n",
    "dataset = RecipeDataset(train_list, tokenizer)\n",
    "\n",
    "# Split into training and validation sets\n",
    "train_size = int(0.9 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "del dataset\n",
    "\n",
    "print('{:>5,} training samples'.format(train_size))\n",
    "print('{:>5,} validation samples'.format(val_size))\n",
    "\n",
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14fa8d5-f2da-4d9b-97a2-696800715e7e",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27379559-d557-4390-93c8-c1ef414c7049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently using device type:  cuda\n"
     ]
    }
   ],
   "source": [
    "# Finetune\n",
    "import torch\n",
    "import random\n",
    "\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "\n",
    "# some parameters I cooked up that work reasonably well\n",
    "\n",
    "epochs = 2\n",
    "\n",
    "# this produces sample output every 100 steps\n",
    "sample_every = 1000\n",
    "# I save the model every 5000 step\n",
    "save_every = 5000\n",
    "# save the model to this file name\n",
    "save_file = 'recipes_generation_model'\n",
    "\n",
    "\n",
    "\n",
    "training_stats = []\n",
    "print(\"Currently using device type: \", device)\n",
    "\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fecd9372-70ac-46db-9725-211b74c2a374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of steps:  110928\n",
      "Currently using device type:  cuda\n",
      "\n",
      "======== Epoch 1 / 2 ========\n",
      "Training...\n",
      "Batch 1,000  of  55,464. Loss: 0.59565669298172.\n",
      "Batch 2,000  of  55,464. Loss: 0.6105248332023621.\n",
      "Batch 3,000  of  55,464. Loss: 0.6797724366188049.\n",
      "Batch 4,000  of  55,464. Loss: 0.5145111083984375.\n",
      "Batch 5,000  of  55,464. Loss: 0.3921472132205963.\n",
      "Batch 6,000  of  55,464. Loss: 0.4083992540836334.\n",
      "Batch 7,000  of  55,464. Loss: 0.5628868937492371.\n",
      "Batch 8,000  of  55,464. Loss: 0.5639268159866333.\n",
      "Batch 9,000  of  55,464. Loss: 0.5016463994979858.\n",
      "Batch 10,000  of  55,464. Loss: 0.6887199878692627.\n",
      "Batch 11,000  of  55,464. Loss: 0.46227481961250305.\n",
      "Batch 12,000  of  55,464. Loss: 0.6451244950294495.\n",
      "Batch 13,000  of  55,464. Loss: 0.5732980966567993.\n",
      "Batch 14,000  of  55,464. Loss: 0.5107012987136841.\n",
      "Batch 15,000  of  55,464. Loss: 0.6942955255508423.\n",
      "Batch 16,000  of  55,464. Loss: 0.32260021567344666.\n",
      "Batch 17,000  of  55,464. Loss: 0.46275025606155396.\n",
      "Batch 18,000  of  55,464. Loss: 0.5112006664276123.\n",
      "Batch 19,000  of  55,464. Loss: 0.5614563822746277.\n",
      "Batch 20,000  of  55,464. Loss: 0.5650010108947754.\n",
      "Batch 21,000  of  55,464. Loss: 0.4661498963832855.\n",
      "Batch 22,000  of  55,464. Loss: 0.6221420168876648.\n",
      "Batch 23,000  of  55,464. Loss: 0.45770102739334106.\n",
      "Batch 24,000  of  55,464. Loss: 0.4017240107059479.\n",
      "Batch 25,000  of  55,464. Loss: 0.43423011898994446.\n",
      "Batch 26,000  of  55,464. Loss: 0.6627912521362305.\n",
      "Batch 27,000  of  55,464. Loss: 0.4967426657676697.\n",
      "Batch 28,000  of  55,464. Loss: 0.40463876724243164.\n",
      "Batch 29,000  of  55,464. Loss: 0.47506067156791687.\n",
      "Batch 30,000  of  55,464. Loss: 0.5150555968284607.\n",
      "Batch 31,000  of  55,464. Loss: 0.33054977655410767.\n",
      "Batch 32,000  of  55,464. Loss: 0.45608463883399963.\n",
      "Batch 33,000  of  55,464. Loss: 0.3716697096824646.\n",
      "Batch 34,000  of  55,464. Loss: 0.51457679271698.\n",
      "Batch 35,000  of  55,464. Loss: 0.35945984721183777.\n",
      "Batch 36,000  of  55,464. Loss: 0.5152595043182373.\n",
      "Batch 37,000  of  55,464. Loss: 0.5423918962478638.\n",
      "Batch 38,000  of  55,464. Loss: 0.4641113579273224.\n",
      "Batch 39,000  of  55,464. Loss: 0.3893982172012329.\n",
      "Batch 40,000  of  55,464. Loss: 0.7957540154457092.\n",
      "Batch 41,000  of  55,464. Loss: 0.42374005913734436.\n",
      "Batch 42,000  of  55,464. Loss: 0.48174604773521423.\n",
      "Batch 43,000  of  55,464. Loss: 0.2783561050891876.\n",
      "Batch 44,000  of  55,464. Loss: 0.603326678276062.\n",
      "Batch 45,000  of  55,464. Loss: 0.5242139101028442.\n",
      "Batch 46,000  of  55,464. Loss: 0.5022168755531311.\n",
      "Batch 47,000  of  55,464. Loss: 0.3936695456504822.\n",
      "Batch 48,000  of  55,464. Loss: 0.5599559545516968.\n",
      "Batch 49,000  of  55,464. Loss: 0.507904589176178.\n",
      "Batch 50,000  of  55,464. Loss: 0.4702237844467163.\n",
      "Batch 51,000  of  55,464. Loss: 0.5738179683685303.\n",
      "Batch 52,000  of  55,464. Loss: 0.4458064138889313.\n",
      "Batch 53,000  of  55,464. Loss: 0.37638238072395325.\n",
      "Batch 54,000  of  55,464. Loss: 0.43789637088775635.\n",
      "Batch 55,000  of  55,464. Loss: 0.731189489364624.\n",
      "\n",
      "  Average training loss: 0.48\n",
      "  Perplexity: 1.61\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 0.45\n",
      "  Validation perplexity: 1.57\n",
      "\n",
      "======== Epoch 2 / 2 ========\n",
      "Training...\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1.05 GiB. GPU 0 has a total capacity of 11.55 GiB of which 498.25 MiB is free. Including non-PyTorch memory, this process has 11.04 GiB memory in use. Of the allocated memory 9.53 GiB is allocated by PyTorch, and 1.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Fine-tune the GPT-2 model on the recipe dataset\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrecipes_generator\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrecipe_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_model\n\u001b[0;32m----> 3\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(history)\n",
      "File \u001b[0;32m~/Documents/documenti uni/sistemi digitali/projects/SmartFridge/AIChefModel/recipes_generator/model/recipe_model.py:276\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_dataset, val_dataset, epochs, batch_size, device, sample_every, save_every, save_file, learning_rate, warmup_steps, epsilon)\u001b[0m\n\u001b[1;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "File \u001b[0;32m~/venv/lib/python3.11/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv/lib/python3.11/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1.05 GiB. GPU 0 has a total capacity of 11.55 GiB of which 498.25 MiB is free. Including non-PyTorch memory, this process has 11.04 GiB memory in use. Of the allocated memory 9.53 GiB is allocated by PyTorch, and 1.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "# Fine-tune the GPT-2 model on the recipe dataset\n",
    "from recipes_generator.model.recipe_model import train_model\n",
    "history = train_model(model, train_dataset, val_dataset, epochs, batch_size, device, save_file=save_file)\n",
    "print(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3a4c1b3-dca6-4fd5-bedc-0ce8955e28c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tokenizer/tokenizer_config.json',\n",
       " 'tokenizer/special_tokens_map.json',\n",
       " 'tokenizer/vocab.json',\n",
       " 'tokenizer/merges.txt',\n",
       " 'tokenizer/added_tokens.json')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(save_file)\n",
    "tokenizer.save_pretrained(\"tokenizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e3bb7a-7ae9-499b-b187-ce6adc2936e4",
   "metadata": {},
   "source": [
    "# Training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12a4cfdb-e831-42c0-b29d-4c4798309d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(50259, 768)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"tokenizer\", bos_token='<|startoftext|>', eos_token='<|endoftext|>', pad_token='<|pad|>')\n",
    "# I'm not really doing anything with the config buheret\n",
    "configuration = GPT2Config.from_pretrained(save_file, output_hidden_states=False)\n",
    "\n",
    "# instantiate the model\n",
    "model = GPT2LMHeadModel.from_pretrained(save_file, config=configuration)\n",
    "\n",
    "# this step is necessary because I've added some tokens (bos_token, etc) to the embeddings\n",
    "# otherwise the tokenizer and model tensors won't match up\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c454b99-c1ba-440d-adb1-f0092ea59af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing...\n",
      "  Validation Loss: 22.15\n",
      "  Validation perplexity: 4175532544.00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from recipes_generator.model.recipe_model import evaluate_model\n",
    "test_dataset = RecipeDataset(test_list, tokenizer, max_length=768)\n",
    "print('Testing...')\n",
    "test_loss, test_perplexity = evaluate_model(model, test_dataset, batch_size, device)\n",
    "test_eval_df = pd.DataFrame(columns = [\"test_loss\", \"test_perplexity\"])\n",
    "test_eval_df['test_loss'] = test_loss\n",
    "test_eval_df['test_perplexity'] = test_perplexity\n",
    "test_eval_df.to_csv(\"test_eval.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b15979-b2ca-4657-904e-c8a1c3a0ef2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_eval_df = pd.DataFrame(columns = [\"epoch\", \"training loss\", \"validation loss\", \"train perplexity\", \"validation perplexity\"])\n",
    "train_loss = []\n",
    "train_perp = []\n",
    "valid_loss = []\n",
    "valid_perp = []\n",
    "for epoch in history:\n",
    "    train_loss.append(epoch['Training Loss'])\n",
    "    train_perp.append(epoch['Training Perplexity'])\n",
    "    valid_loss.append(epoch['Valid. Loss'])\n",
    "    valid_perp.append(epoch['Valid. Perplexity'])\n",
    "\n",
    "training_eval_df['epoch'] = [x for x in range(len(training_stats))]\n",
    "training_eval_df['training loss'] = train_loss\n",
    "training_eval_df['validation loss'] = valid_loss\n",
    "training_eval_df['train perplexity'] = train_perp\n",
    "training_eval_df['validation perplexity'] = valid_perp\n",
    "\n",
    "training_eval_df.to_csv(\"train_eval.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6a1d13-d781-4618-a7c6-aa118724af5a",
   "metadata": {},
   "source": [
    "# Examples of generated recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5afe7d8-de8c-46ff-b728-54bc5d71c000",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_loaded = GPT2LMHeadModel.from_pretrained(\"model\", config=configuration, ignore_mismatched_sizes=True)\n",
    "def infer(prompt, model, tokenizer):\n",
    "    input = f\"<|startoftext|>Prompt: {prompt.strip()}\"\n",
    "    input = tokenizer(input, return_tensors=\"pt\")\n",
    "    input_ids      = input[\"input_ids\"]\n",
    "    attention_mask = input[\"attention_mask\"]\n",
    "\n",
    "    output = model.generate(input_ids.to(device),\n",
    "                            attention_mask=attention_mask.to(device),\n",
    "                            max_new_tokens=200,\n",
    "                            num_beams=5, \n",
    "                            no_repeat_ngram_size=2, \n",
    "                            max_length = 600,\n",
    "                            num_return_sequences=1,\n",
    "                            eos_token_id=tokenizer.eos_token_id,\n",
    "                            do_sample = True, top_k = 100, top_p = 0.85)\n",
    "    output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d1670bb-8e07-41de-85de-ed5512a8cf16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=200) and `max_length`(=600) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=200) and `max_length`(=600) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: chocolate,flour,sugar, eggs, vanilla essence, self-raising flour, cocoa powder\n",
      "Title: Chocolate Mousse Cake\n",
      "Ingredients: 200 chocolate\n",
      "Servings: 1\n",
      "Instructions: Preheat oven to 180°C. Grease and line a 20cm springform cake tin. Melt chocolate in a heatproof bowl over a pan of simmering water. Remove from heat and stir in sugar until dissolved. Add eggs one at a time beating well after each addition. Stir in vanilla. Fold in sifted flour and cocoa. Pour into prepared tin and bake for 30-35 minutes or until a skewer inserted into the centre comes out clean. Cool in the tin for 10 minutes then remove to a wire rack to cool completely. To make the mousse cream the cream until soft peaks form. Gradually add the sugar and continue to beat until stiff and glossy. \n",
      "Spread over the top of the cake.\n",
      "Cook time: PT35M\n",
      "Preparation time : PT15H\n",
      "Total time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=200) and `max_length`(=600) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: chicken, flour, lemon, parmesan cheese, butter, margarine\n",
      "Title: Chicken Parmesan\n",
      "Ingredients: 1 chicken\n",
      "Servings: 4\n",
      "Instructions: Preheat oven to 350°F. Wash chicken and pat dry with paper towels. Sprinkle with salt and pepper. Place chicken in a shallow baking dish. In a small bowl combine the flour and the lemon juice. Dredge chicken pieces in flour mixture. Melt the butter and pour over chicken. Bake uncovered for 45 minutes or until chicken is tender.\n",
      "Cook time: PT45M\n",
      "Preparation time : PT10M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=200) and `max_length`(=600) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: courgette, aubergine,flour,lemon, milk, eggs, parmesan cheese, butter, margarine, olive oil, onion, garlic clove, celery, carrot, parsnip, green beans, zucchini, tomatoes, eggplant, flour, salt, pepper, nutmeg, cayenne pepper\n",
      "Title: Vegetable Frittata\n",
      "Ingredients: 1/2 cour Vegie,  1 auornine\n",
      "Servings: 4\n",
      "Instructions: Preheat the oven to 180C/350F/gas mark 4. Grease an ovenproof dish with butter and line with baking paper. Heat the oil in a frying pan and add the onion and garlic and cook for a few minutes until soft but not coloured. Add the veg and saute for another minute or two. Pour in the stock and bring to the boil. Reduce the heat and simmer for 10-15 minutes or until all the liquid has evaporated. Whisk the egg yolks with a little of the milk and\n",
      "Prompt: courgette, pepper, flour, mid-seasoned cheese, butter, margarine\n",
      "Title: Courgettes Au Gratin\n",
      "Ingredients: 1/2 courpe,  pepper\n",
      "Servings: 4\n",
      "Instructions: Preheat oven to 180°C. Grease a shallow 2 litre baking dish with the butter. Arrange courgtes in a single layer in the dish. Sprinkle with pepper and sprinkle with cheese. Pour cream over all. Cover with foil and bake for 30 minutes. Uncover and cook for a further 10 minutes or until the top is golden and bubbling. Serve hot.\n",
      "Cook time: PT40M\n",
      "Preparation time : PT10M\n"
     ]
    }
   ],
   "source": [
    "prompts = ['chocolate,flour,sugar', 'chicken, flour, lemon, parmesan cheese', 'courgette, aubergine,flour,lemon', 'courgette, pepper, flour, mid-seasoned cheese']\n",
    "generated_recipes = []\n",
    "for p in prompts:    \n",
    "    recipe = infer(p, model, tokenizer)\n",
    "    print(recipe)\n",
    "    generated_recipes.append(recipe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43c3bb38-a1f6-4052-852d-dcf6e0ab7a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=200) and `max_length`(=600) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=200) and `max_length`(=600) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: chocolate,flour,sugar, eggs, vanilla essence, self raising flour, cocoa powder\n",
      "Title: Chocolate Mousse Cake\n",
      "Ingredients: 200 chocolate\n",
      "Servings: 1\n",
      "Instructions: Preheat oven to 180°C. Grease and line the base of a 20cm springform cake tin. Melt the chocolate in a heatproof bowl over a pan of simmering water. Remove from the heat and stir in the sugar. Add the egg yolks one at a time beating well after each addition. Beat the cream until soft peaks form. Fold the melted chocolate into the whipped cream. Sift the self-raising flour and cocoa into a bowl and fold in gently. In a clean bowl beat egg whites until stiff and glossy. Gently fold the meringue into chocolate mixture. Pour the mixture into prepared tin and bake for 30-35 minutes or until a skewer comes out clean. \n",
      "Leave to cool for 10 minutes then turn out onto a wire rack and cool completely.\n",
      "Cook time:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=200) and `max_length`(=600) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: chicken, flour, lemon, parmesan cheese, butter, margarine\n",
      "Title: Chicken Parmesan\n",
      "Ingredients: 1 chicken\n",
      "Servings: 4\n",
      "Instructions: Preheat oven to 350°F. Wash chicken and pat dry. Sprinkle with salt and pepper. Melt butter in baking dish. Place chicken in dish and sprinkle with cheese. Bake for 30 minutes or until chicken is done.\n",
      "Cook time: PT30M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=200) and `max_length`(=600) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: courgette, aubergine,flour,lemon, onion, garlic cloves, cumin seed, mustard seeds, garam masala, turmeric powder, salt, tomatoes, tomato puree, water, green chilies, coriander leaves\n",
      "Title: Roasted Vegetable Curry\n",
      "Ingredients: 1/2 - 3/4 cournut,  1 -2 Auberginine\n",
      "Servings: 4\n",
      "Instructions: Preheat oven to 180°C. Place all the vegetables in a large roasting tin. Sprinkle with salt and pepper. Roast for 30 minutes. Remove from the oven and set aside. In a frying pan heat the oil and fry the onion until soft. Add the garlic and saute for a further 30 seconds. Stir in the spices and cook for 1 minute. Return the veg to the pan and add the pureed tomatoes and water. Bring to a boil and then reduce the heat and simmer for 10-15 minutes or until the veggies are tender.\n",
      "Cook time: PT45M\n",
      "Prompt: courgette, pepper, flour, mid-seasoned cheese, butter, margarine\n",
      "Title: Courgettes Au Gratin\n",
      "Ingredients: 1/2 courpe,  1 pepper\n",
      "Servings: 4\n",
      "Instructions: Preheat oven to 180°C. Grease a shallow 1.5 litre casserole dish. Sprinkle with half the cheese. Repeat layers. Melt the butter in a frying pan and fry the vegetables for 5 minutes or until soft. Pour into the dish and sprinkle with the remaining cheese and breadcrumbs. Bake for 30 minutes.\n",
      "Cook time: PT30M\n",
      "Preparation time : PT10M\n"
     ]
    }
   ],
   "source": [
    "prompts = ['chocolate,flour,sugar', 'chicken, flour, lemon, parmesan cheese', 'courgette, aubergine,flour,lemon', 'courgette, pepper, flour, mid-seasoned cheese']\n",
    "model_loaded = GPT2LMHeadModel.from_pretrained(save_file, ignore_mismatched_sizes=True).to(device)\n",
    "tokenizer_loaded = GPT2TokenizerFast.from_pretrained(\"tokenizer\")\n",
    "generated_recipes_from_loaded = []\n",
    "for p in prompts:    \n",
    "    recipe = infer(p, model_loaded, tokenizer_loaded)\n",
    "    print(recipe)\n",
    "    generated_recipes_from_loaded.append(recipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94f63a5d-889b-4881-a033-5429ee46cc1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-25 06:32:08.560373: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-25 06:32:08.578153: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-25 06:32:09.294781: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-04-25 06:32:10.053002: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-25 06:32:10.069654: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-25 06:32:10.073149: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-25 06:32:10.078697: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-25 06:32:10.082103: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-25 06:32:10.085405: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-25 06:32:10.088417: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-25 06:32:10.091736: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-25 06:32:10.095113: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-25 06:32:10.098041: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2428 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpnbnu_xxv/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpnbnu_xxv/assets\n",
      "2024-04-25 06:32:36.434551: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2024-04-25 06:32:36.434585: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2024-04-25 06:32:36.435036: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmpnbnu_xxv\n",
      "2024-04-25 06:32:36.441262: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
      "2024-04-25 06:32:36.441270: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /tmp/tmpnbnu_xxv\n",
      "2024-04-25 06:32:36.460126: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:375] MLIR V1 optimization pass is not enabled\n",
      "2024-04-25 06:32:36.464984: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2024-04-25 06:32:36.593678: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /tmp/tmpnbnu_xxv\n",
      "2024-04-25 06:32:36.642309: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 207274 microseconds.\n",
      "2024-04-25 06:32:36.726133: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "163979940"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import TFGPT2LMHeadModel\n",
    "model_loaded = TFGPT2LMHeadModel.from_pretrained(save_file, ignore_mismatched_sizes=True)\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_loaded)\n",
    "\n",
    "# For FP16 quantization:\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_types = [tf.float16]\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "open(\"recipes_generator.tflite\", \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c01c6c-8caf-47b3-94f3-5ba08e343a73",
   "metadata": {},
   "source": [
    "## Knowledge Distillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6970f19-063a-406b-aad7-9d650e0dcdbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "2024-04-25 17:47:41.646141: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-25 17:47:41.650527: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-25 17:47:41.654059: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-25 17:47:41.659207: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-25 17:47:41.662656: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-25 17:47:41.665952: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-25 17:47:41.773012: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-25 17:47:41.774251: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-25 17:47:41.775395: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-25 17:47:41.776522: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8857 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# Dummy Examples \n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"tokenizer\", bos_token='<|startoftext|>', eos_token='<|endoftext|>', pad_token='<|pad|>')\n",
    "input_encoded = tokenizer(\"<|startoftext|>Prompt:eggs,parmesan cheese\", return_tensors=\"tf\")\n",
    "\n",
    "output = []\n",
    "for i in range(0):#len(input_encoded['input_ids'])):\n",
    "    input_vector = tf.constant([[input_encoded['input_ids'][0][i].numpy()]])\n",
    "    # input type ids\n",
    "    input_ids = input_vector#input_encoded['input_ids'][i]\n",
    "    interpreter.set_tensor(\n",
    "        input_details[1]['index'],\n",
    "        input_ids,\n",
    "    )\n",
    "    \n",
    "    # input_mask\n",
    "    input_mask = input_vector#input_encoded['attention_mask']\n",
    "    interpreter.set_tensor(\n",
    "        input_details[0]['index'],\n",
    "        input_mask,\n",
    "    )\n",
    "    \n",
    "    # input ids\n",
    "    \n",
    "    \n",
    "    # Invoke inputs\n",
    "    interpreter.invoke()\n",
    "    # Take last output\n",
    "    tflite_output = interpreter.get_tensor(output_details[-1]['index'])\n",
    "    \n",
    "    # Keras Model outputs .\n",
    "    #model_inputs = {'input_ids': input_ids, 'input_mask': input_mask, 'input_type_ids': input_type_ids}\n",
    "    #model_outputs = model(model_inputs)\n",
    "    \n",
    "    # We need a slightly higher rtol here to assert :-)\n",
    "    #tf.debugging.assert_near(tflite_output, model_outputs['token_embeddings'], rtol=3.0)\n",
    "    #print(\"Outputs asserted and succesful:  ✅\")\n",
    "    #print(tflite_output)\n",
    "    output.append(tflite_output)\n",
    "\n",
    "#print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1eb9f03f-f8a5-4bbe-86e3-90f35a6fafa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[50257 24129   457    25 33856    82    11    79  1670 42890  9891]], shape=(1, 11), dtype=int32)\n",
      "{'name': 'serving_default_input_ids:0', 'index': 1, 'shape': array([1, 1], dtype=int32), 'shape_signature': array([-1, -1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n"
     ]
    }
   ],
   "source": [
    "print(input_encoded['input_ids'])\n",
    "print(input_details[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "493c80f0-c83c-482e-a627-e452b4648460",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-30 17:37:00.057454: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-30 17:37:00.082110: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-30 17:37:00.570297: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-04-30 17:37:01.522129: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-30 17:37:01.528506: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-30 17:37:01.532040: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-30 17:37:01.536851: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-30 17:37:01.540355: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-30 17:37:01.543614: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-30 17:37:01.655098: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-30 17:37:01.656448: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-30 17:37:01.657582: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-30 17:37:01.658707: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10168 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFGPT2LMHeadModel\n",
    "model_loaded = TFGPT2LMHeadModel.from_pretrained(\"recipes_generation_model\", ignore_mismatched_sizes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53ab12aa-a0d7-4138-a3aa-a9efd42def56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_tflite_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_tflite_model/assets\n"
     ]
    }
   ],
   "source": [
    "model_loaded.save(\"saved_tflite_model\", save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bc87bce-a9c6-438b-86cb-b7a2a3c667c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1714491520.237830   16127 tf_tfl_flatbuffer_helpers.cc:390] Ignored output_format.\n",
      "W0000 00:00:1714491520.237858   16127 tf_tfl_flatbuffer_helpers.cc:393] Ignored drop_control_dependency.\n",
      "2024-04-30 17:38:40.238168: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: saved_tflite_model\n",
      "2024-04-30 17:38:40.244622: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-04-30 17:38:40.244634: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: saved_tflite_model\n",
      "2024-04-30 17:38:40.298010: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
      "2024-04-30 17:38:40.303233: I tensorflow/cc/saved_model/loader.cc:234] Restoring SavedModel bundle.\n",
      "2024-04-30 17:38:40.455321: I tensorflow/cc/saved_model/loader.cc:218] Running initialization op on SavedModel bundle at path: saved_tflite_model\n",
      "2024-04-30 17:38:40.501811: I tensorflow/cc/saved_model/loader.cc:317] SavedModel load for tags { serve }; Status: success: OK. Took 263646 microseconds.\n",
      "2024-04-30 17:38:40.568755: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFlite conversion succesful\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(\"saved_tflite_model\") # path to the SavedModel directory\n",
    "converter.experimental_new_converter = True\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_types = [tf.float16]\n",
    "\n",
    "open(\"new_saved_model.tflite\".format(\"distilbert/distilgpt2\"), \"wb\").write(tflite_model)\n",
    "print(\"TFlite conversion succesful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4c736466-6e56-4233-b934-31dae3dcd6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_loaded = GPT2LMHeadModel.from_pretrained(\"model\", config=configuration, ignore_mismatched_sizes=True)\n",
    "def infer(prompt, model, tokenizer, max_length):\n",
    "    input = f\"<|startoftext|>Prompt: {prompt}\"\n",
    "    input = tokenizer(input, return_tensors=\"pt\")\n",
    "    input_ids      = input[\"input_ids\"]\n",
    "    attention_mask = input[\"attention_mask\"]\n",
    "\n",
    "    output = model.generate(input_ids.to(device),\n",
    "                            attention_mask=attention_mask.to(device),\n",
    "                            max_new_tokens=max_length,\n",
    "                            num_beams=5, \n",
    "                            no_repeat_ngram_size=2, \n",
    "                            max_length = 600,\n",
    "                            num_return_sequences=1,\n",
    "                            eos_token_id=tokenizer.eos_token_id,\n",
    "                            do_sample = True, top_k = 100, top_p = 0.85)\n",
    "    output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef0115b4-f297-4438-acb3-8090f2e391f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-25 17:58:11.502703: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-25 17:58:11.507252: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2024-04-25 17:58:11.507305: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-04-25 17:58:11.507649: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-25 17:58:11.510971: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-25 17:58:11.514313: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-25 17:58:11.517323: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-25 17:58:11.520572: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-25 17:58:11.523877: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8857 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "W0000 00:00:1714060694.241248   25447 tf_tfl_flatbuffer_helpers.cc:390] Ignored output_format.\n",
      "W0000 00:00:1714060694.241265   25447 tf_tfl_flatbuffer_helpers.cc:393] Ignored drop_control_dependency.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid signature_key provided.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 30\u001b[0m\n\u001b[1;32m     28\u001b[0m converter\u001b[38;5;241m.\u001b[39m_experimental_guarantee_all_funcs_one_use \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     29\u001b[0m generate_tflite \u001b[38;5;241m=\u001b[39m converter\u001b[38;5;241m.\u001b[39mconvert()\n\u001b[0;32m---> 30\u001b[0m \u001b[43mrun_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m<|startoftext|>Prompt:aubergine,courgette,chicken\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerate_tflite\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 16\u001b[0m, in \u001b[0;36mrun_inference\u001b[0;34m(input, generate_tflite)\u001b[0m\n\u001b[1;32m     11\u001b[0m interp \u001b[38;5;241m=\u001b[39m interpreter\u001b[38;5;241m.\u001b[39mInterpreterWithCustomOps(\n\u001b[1;32m     12\u001b[0m     model_content\u001b[38;5;241m=\u001b[39mgenerate_tflite,\n\u001b[1;32m     13\u001b[0m     custom_op_registerers\u001b[38;5;241m=\u001b[39mtf_text\u001b[38;5;241m.\u001b[39mtflite_registrar\u001b[38;5;241m.\u001b[39mSELECT_TFTEXT_OPS)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(interp\u001b[38;5;241m.\u001b[39mget_signature_list())\n\u001b[0;32m---> 16\u001b[0m generator \u001b[38;5;241m=\u001b[39m \u001b[43minterp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_signature_runner\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mserving_default\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m output \u001b[38;5;241m=\u001b[39m generator(prompt\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;28minput\u001b[39m]))\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mGenerated with TFLite:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, output[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_0\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m~/venv/lib/python3.11/site-packages/tensorflow/lite/python/interpreter.py:859\u001b[0m, in \u001b[0;36mInterpreter.get_signature_runner\u001b[0;34m(self, signature_key)\u001b[0m\n\u001b[1;32m    857\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    858\u001b[0m     signature_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signature_defs))\n\u001b[0;32m--> 859\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSignatureRunner\u001b[49m\u001b[43m(\u001b[49m\u001b[43minterpreter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature_key\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv/lib/python3.11/site-packages/tensorflow/lite/python/interpreter.py:207\u001b[0m, in \u001b[0;36mSignatureRunner.__init__\u001b[0;34m(self, interpreter, signature_key)\u001b[0m\n\u001b[1;32m    205\u001b[0m signature_defs \u001b[38;5;241m=\u001b[39m interpreter\u001b[38;5;241m.\u001b[39m_get_full_signature_list()\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m signature_key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m signature_defs:\n\u001b[0;32m--> 207\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInvalid signature_key provided.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signature_def \u001b[38;5;241m=\u001b[39m signature_defs[signature_key]\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signature_def[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mitems()\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid signature_key provided."
     ]
    }
   ],
   "source": [
    "from tensorflow.lite.python import interpreter\n",
    "import tensorflow_text as tf_text\n",
    "@tf.function(input_signature=[tf.TensorSpec(shape=(None, None), dtype=tf.int32)])\n",
    "def concrete_function(input_ids):\n",
    "    return model_loaded(input_ids)\n",
    "\n",
    "# Get the concrete function\n",
    "dummy_input = tf.constant([[1, 2, 3]])\n",
    "concrete_func = concrete_function.get_concrete_function(dummy_input)\n",
    "def run_inference(input, generate_tflite):\n",
    "    interp = interpreter.InterpreterWithCustomOps(\n",
    "        model_content=generate_tflite,\n",
    "        custom_op_registerers=tf_text.tflite_registrar.SELECT_TFTEXT_OPS)\n",
    "    print(interp.get_signature_list())\n",
    "    \n",
    "    generator = interp.get_signature_runner('serving_default')\n",
    "    output = generator(prompt=np.array([input]))\n",
    "    print(\"\\nGenerated with TFLite:\\n\", output[\"output_0\"])\n",
    "#gpt2_lm.jit_compile = False\n",
    "converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func],\n",
    "                                                            model_loaded)\n",
    "converter.target_spec.supported_ops = [\n",
    "  tf.lite.OpsSet.TFLITE_BUILTINS, # enable TensorFlow Lite ops.\n",
    "  tf.lite.OpsSet.SELECT_TF_OPS # enable TensorFlow ops.\n",
    "]\n",
    "converter.allow_custom_ops = True\n",
    "converter.target_spec.experimental_select_user_tf_ops = [\"UnsortedSegmentJoin\", \"UpperBound\"]\n",
    "converter._experimental_guarantee_all_funcs_one_use = True\n",
    "generate_tflite = converter.convert()\n",
    "run_inference(\"<|startoftext|>Prompt:aubergine,courgette,chicken\", generate_tflite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6b834f4-95a2-4a4d-afa1-f354393179a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n\n    ValueError: Got a non-Tensor value (<tf.Tensor 'StatefulPartitionedCall:1' shape=(2, None, 12, None, 64) dtype=float32>, <tf.Tensor 'StatefulPartitionedCall:2' shape=(2, None, 12, None, 64) dtype=float32>, <tf.Tensor 'StatefulPartitionedCall:3' shape=(2, None, 12, None, 64) dtype=float32>, <tf.Tensor 'StatefulPartitionedCall:4' shape=(2, None, 12, None, 64) dtype=float32>, <tf.Tensor 'StatefulPartitionedCall:5' shape=(2, None, 12, None, 64) dtype=float32>, <tf.Tensor 'StatefulPartitionedCall:6' shape=(2, None, 12, None, 64) dtype=float32>) for key 'past_key_values' in the output of the function __inference_concrete_function_27785 used to generate the SavedModel signature 'serving_default'. Outputs for functions used as signatures must be a single Tensor, a sequence of Tensors, or a dictionary from string to Tensor.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel_loaded\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrecipes_generation_model_new\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mserving_default\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mconcrete_function\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv/lib/python3.11/site-packages/tf_keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filesjaxqkrm.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__signature_wrapper\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(_normalize_outputs), (ag__\u001b[38;5;241m.\u001b[39mld(structured_outputs), ag__\u001b[38;5;241m.\u001b[39mld(signature_function)\u001b[38;5;241m.\u001b[39mname, ag__\u001b[38;5;241m.\u001b[39mld(signature_key)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n\n    ValueError: Got a non-Tensor value (<tf.Tensor 'StatefulPartitionedCall:1' shape=(2, None, 12, None, 64) dtype=float32>, <tf.Tensor 'StatefulPartitionedCall:2' shape=(2, None, 12, None, 64) dtype=float32>, <tf.Tensor 'StatefulPartitionedCall:3' shape=(2, None, 12, None, 64) dtype=float32>, <tf.Tensor 'StatefulPartitionedCall:4' shape=(2, None, 12, None, 64) dtype=float32>, <tf.Tensor 'StatefulPartitionedCall:5' shape=(2, None, 12, None, 64) dtype=float32>, <tf.Tensor 'StatefulPartitionedCall:6' shape=(2, None, 12, None, 64) dtype=float32>) for key 'past_key_values' in the output of the function __inference_concrete_function_27785 used to generate the SavedModel signature 'serving_default'. Outputs for functions used as signatures must be a single Tensor, a sequence of Tensors, or a dictionary from string to Tensor.\n"
     ]
    }
   ],
   "source": [
    "model_loaded.save(\"recipes_generation_model_new\", signatures={\"serving_default\": concrete_function})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0141abc-d3fb-4f53-b36c-744bb1404b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp5yvznmbu/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp5yvznmbu/assets\n",
      "W0000 00:00:1714137743.451712   49758 tf_tfl_flatbuffer_helpers.cc:390] Ignored output_format.\n",
      "W0000 00:00:1714137743.452121   49758 tf_tfl_flatbuffer_helpers.cc:393] Ignored drop_control_dependency.\n",
      "2024-04-26 15:22:23.453014: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmp5yvznmbu\n",
      "2024-04-26 15:22:23.459155: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-04-26 15:22:23.459168: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmp5yvznmbu\n",
      "2024-04-26 15:22:23.518688: I tensorflow/cc/saved_model/loader.cc:234] Restoring SavedModel bundle.\n",
      "2024-04-26 15:22:24.087489: I tensorflow/cc/saved_model/loader.cc:218] Running initialization op on SavedModel bundle at path: /tmp/tmp5yvznmbu\n",
      "2024-04-26 15:22:24.140309: I tensorflow/cc/saved_model/loader.cc:317] SavedModel load for tags { serve }; Status: success: OK. Took 687360 microseconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "163972432"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import TFGPT2LMHeadModel, GPT2Config\n",
    "configuration = GPT2Config.from_pretrained(\"recipes_generation_model\", max_length=768)\n",
    "model_loaded = TFGPT2LMHeadModel.from_pretrained(\"recipes_generation_model\")#, ignore_mismatched_sizes=True)\n",
    "config = model_loaded.config\n",
    "\n",
    "# Print the input and output sizes\n",
    "#print(\"Input size:\", config.n_embd)  # Dimension of the token embeddings\n",
    "#print(\"Output size:\", config.vocab_size)\n",
    "input_spec = tf.keras.Input([1,768], batch_size=1, dtype=tf.int32)\n",
    "model_loaded._set_inputs(input_spec, training=False)\n",
    "print(model_loaded.inputs)\n",
    "print(model_loaded.outputs)\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_loaded)\n",
    "\n",
    "# For FP16 quantization:\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_types = [tf.float16]\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS]\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "open(\"new_saved_model.tflite\", \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd99acc9-7f09-401c-aea7-72b83e55265a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_keras.src.layers.core.embedding.Embedding at 0x7fd161866990>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_loaded.get_output_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eefa5d6b-af59-48eb-acec-8a6643dabf70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "WARNING: Attempting to use a delegate that only supports static-sized tensors with a graph that has dynamic-sized tensors (tensor#193 is a dynamic-sized tensor).\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "gather index out of boundsNode number 104 (GATHER) failed to invoke.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m interpreter\u001b[38;5;241m.\u001b[39mset_tensor(input_details[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m], input_data)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Run inference\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m \u001b[43minterpreter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Get output tensor\u001b[39;00m\n\u001b[1;32m     23\u001b[0m output_data \u001b[38;5;241m=\u001b[39m interpreter\u001b[38;5;241m.\u001b[39mget_tensor(output_details[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/venv/lib/python3.11/site-packages/tensorflow/lite/python/interpreter.py:941\u001b[0m, in \u001b[0;36mInterpreter.invoke\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Invoke the interpreter.\u001b[39;00m\n\u001b[1;32m    930\u001b[0m \n\u001b[1;32m    931\u001b[0m \u001b[38;5;124;03mBe sure to set the input sizes, allocate tensors and fill values before\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    938\u001b[0m \u001b[38;5;124;03m  ValueError: When the underlying interpreter fails raise ValueError.\u001b[39;00m\n\u001b[1;32m    939\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    940\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_safe()\n\u001b[0;32m--> 941\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpreter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: gather index out of boundsNode number 104 (GATHER) failed to invoke."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the TFLite model\n",
    "interpreter = tf.lite.Interpreter(model_path=\"new_saved_model.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output details\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Prepare input data\n",
    "input_shape = input_details[0]['shape']\n",
    "input_data = np.random.randint(0, 50259, size=input_shape, dtype=np.int32)  # Example input data\n",
    "\n",
    "# Set input tensor\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "# Run inference\n",
    "interpreter.invoke()\n",
    "\n",
    "# Get output tensor\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "\n",
    "# Print output\n",
    "print(\"Output data shape:\", output_data.shape)\n",
    "print(\"Output data:\", output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3cc35f6-1d33-4abf-b0e1-93f987846bd4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'distribution_strategy_context' from 'tensorflow.python.distribute' (/home/dagus/venv/lib/python3.11/site-packages/tensorflow/python/distribute/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgpt2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GPT2Tokenizer, GPT2Config\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Initialize tokenizer and model\u001b[39;00m\n",
      "File \u001b[0;32m~/venv/lib/python3.11/site-packages/tf_transformers/models/__init__.py:17\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# coding=utf-8\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Copyright 2021 TF-Transformers Authors.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# All Rights Reserved.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01malbert\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     18\u001b[0m     AlbertConfig,\n\u001b[1;32m     19\u001b[0m     AlbertEncoder,\n\u001b[1;32m     20\u001b[0m     AlbertModel,\n\u001b[1;32m     21\u001b[0m     AlbertTokenizerLayer,\n\u001b[1;32m     22\u001b[0m     AlbertTokenizerTFText,\n\u001b[1;32m     23\u001b[0m )\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbart\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BartConfig, BartEncoder, BartModel\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbert\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BertConfig, BertEncoder, BertModel\n",
      "File \u001b[0;32m~/venv/lib/python3.11/site-packages/tf_transformers/models/albert/__init__.py:17\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# coding=utf-8\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Copyright 2021 TF-Transformers Authors.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# All Rights Reserved.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01malbert\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01malbert\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AlbertEncoder\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01malbert\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01malbert_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AlbertModel\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01malbert\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfiguration_albert\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AlbertConfig\n",
      "File \u001b[0;32m~/venv/lib/python3.11/site-packages/tf_transformers/models/albert/albert.py:25\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mabsl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m logging\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_activation\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LegacyLayer, LegacyModel\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BiasLayer, MaskedLM, dense_einsum\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmask\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CausalMask, SelfAttentionMask, prefix_mask\n",
      "File \u001b[0;32m~/venv/lib/python3.11/site-packages/tf_transformers/core/__init__.py:17\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# coding=utf-8\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Copyright 2021 TF-Transformers Authors.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# All Rights Reserved.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchainer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ClassificationChainer, TextGenerationChainer\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlegacy_layer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LegacyLayer\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlegacy_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LegacyModel\n",
      "File \u001b[0;32m~/venv/lib/python3.11/site-packages/tf_transformers/core/chainer.py:24\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlegacy_layer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LegacyLayer\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlegacy_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LegacyModel\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mTextGenerationChainer\u001b[39;00m(LegacyLayer):\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, tokenizer_model, model, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n",
      "File \u001b[0;32m~/venv/lib/python3.11/site-packages/tf_transformers/core/legacy_model.py:24\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mabsl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m logging\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlegacy_compile\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LossesContainer, MetricsContainer\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlegacy_module\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LegacyModule, LegacyModuleCustom\n\u001b[1;32m     27\u001b[0m logging\u001b[38;5;241m.\u001b[39mset_verbosity(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mINFO\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/venv/lib/python3.11/site-packages/tf_transformers/core/legacy_compile.py:23\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcopy\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msix\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribution_strategy_context \u001b[38;5;28;01mas\u001b[39;00m ds_context\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m losses \u001b[38;5;28;01mas\u001b[39;00m losses_mod\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m metrics \u001b[38;5;28;01mas\u001b[39;00m metrics_mod\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'distribution_strategy_context' from 'tensorflow.python.distribute' (/home/dagus/venv/lib/python3.11/site-packages/tensorflow/python/distribute/__init__.py)"
     ]
    }
   ],
   "source": [
    "from tf_transformers.models.gpt2 import *\n",
    "from transformers import GPT2Tokenizer, GPT2Config\n",
    "\n",
    "# Initialize tokenizer and model\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"tokenizer\")\n",
    "config = GPT2Config.from_pretrained(\"recipes_generation_model\")\n",
    "model = convert.convert_gpt2_pt(\"recipes_generation_model\", name=\"gpt2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "482e0324-afd7-41d3-b2a8-85a99c7237e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFGPT2LMHeadModel\n",
    "model = TFGPT2LMHeadModel.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8281ccfc-312f-4eb3-ab35-fad4c01bd5ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The layer tfgpt2lm_head_model_6 has never been called and thus has no defined input shape.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_input_shape_at\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv/lib/python3.11/site-packages/tf_keras/src/engine/base_layer.py:1981\u001b[0m, in \u001b[0;36mLayer.get_input_shape_at\u001b[0;34m(self, node_index)\u001b[0m\n\u001b[1;32m   1964\u001b[0m \u001b[38;5;129m@doc_controls\u001b[39m\u001b[38;5;241m.\u001b[39mdo_not_doc_inheritable\n\u001b[1;32m   1965\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_input_shape_at\u001b[39m(\u001b[38;5;28mself\u001b[39m, node_index):\n\u001b[1;32m   1966\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Retrieves the input shape(s) of a layer at a given node.\u001b[39;00m\n\u001b[1;32m   1967\u001b[0m \n\u001b[1;32m   1968\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1979\u001b[0m \u001b[38;5;124;03m      RuntimeError: If called in Eager mode.\u001b[39;00m\n\u001b[1;32m   1980\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1981\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_node_attribute_at_index\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1982\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnode_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput_shapes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput shape\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m   1983\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv/lib/python3.11/site-packages/tf_keras/src/engine/base_layer.py:2959\u001b[0m, in \u001b[0;36mLayer._get_node_attribute_at_index\u001b[0;34m(self, node_index, attr, attr_name)\u001b[0m\n\u001b[1;32m   2936\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Private utility to retrieves an attribute (e.g. inputs) from a node.\u001b[39;00m\n\u001b[1;32m   2937\u001b[0m \n\u001b[1;32m   2938\u001b[0m \u001b[38;5;124;03mThis is used to implement the methods:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2956\u001b[0m \u001b[38;5;124;03m    ValueError: If the index provided does not match any node.\u001b[39;00m\n\u001b[1;32m   2957\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2958\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inbound_nodes:\n\u001b[0;32m-> 2959\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   2960\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe layer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has never been called \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2961\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand thus has no defined \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2962\u001b[0m     )\n\u001b[1;32m   2963\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inbound_nodes) \u001b[38;5;241m>\u001b[39m node_index:\n\u001b[1;32m   2964\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2965\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsked to get \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m at node \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2966\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but the layer has only \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2967\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inbound_nodes)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m inbound nodes.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2968\u001b[0m     )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The layer tfgpt2lm_head_model_6 has never been called and thus has no defined input shape."
     ]
    }
   ],
   "source": [
    "model.get_input_shape_at(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f45e91c-9e45-4166-8190-4a5a1f4e9d75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
