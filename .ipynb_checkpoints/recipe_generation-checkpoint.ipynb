{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ee3ebdd-9338-4da0-8221-ec18150520ea",
   "metadata": {},
   "source": [
    "# Necessary imports for recipes generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4343246-a723-4ac2-989c-44e793e5f3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, GPT2Config, GPT2TokenizerFast\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from recipes_generator.data.recipe_dataset import RecipeDataset, load_preprocess_raw_json_data, load_preprocess_raw_csv_data\n",
    "import recipes_generator.model.recipe_model\n",
    "from torch.optim import AdamW\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from tqdm import tqdm\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36e4ccc-ec4b-406e-b058-337d259e2531",
   "metadata": {},
   "source": [
    "# Dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f11d1a42-dee8-4960-a76a-4e8ee23880d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes1 = load_preprocess_raw_json_data('recipes_generator/data/recipes_raw_nosource_ar.json')\n",
    "recipes2 = load_preprocess_raw_json_data('recipes_generator/data/recipes_raw_nosource_epi.json')\n",
    "recipes3 = load_preprocess_raw_json_data('recipes_generator/data/recipes_raw_nosource_fn.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62d066f3-843a-4706-a59d-cda4e6d78a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes4 = load_preprocess_raw_csv_data('recipes_generator/data/recipes_general.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a48afba-1fe2-4ec0-af92-c377dd7fb6a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|startoftext|>Prompt: blueberries, granulated sugar, vanilla yogurt, lemon juice\n",
      "Title: Low-Fat Berry Blue Frozen Dessert\n",
      "Ingredients: \n",
      "- 4 cups granulated sugar\n",
      "- 1/4 teaspoon vanilla yogurt\n",
      "- 1 teaspoon lemon juice\n",
      "- 1 cup blueberries\n",
      "Servings: 4\n",
      "Instructions: Toss 2 cups berries with sugar. Let stand for 45 minutes stirring occasionally. Transfer berry-sugar mixture to food processor. Add yogurt and process until smooth. Strain through fine sieve. Pour into baking pan (or transfer to ice cream maker and process according to manufacturers' directions). Freeze uncovered until edges are solid but centre is soft.  Transfer to processor and blend until smooth again. Return to pan and freeze until edges are solid. Transfer to processor and blend until smooth again. \n",
      "Fold in remaining 2 cups of blueberries. Pour into plastic mold and freeze overnight. Let soften slightly to serve.\n",
      "Cook time: 24 h \n",
      "Preparation time: 45 min \n",
      "Total time: 24 h 45 min <|endoftext|>\n",
      "<|startoftext|>Prompt: saffron, milk, hot green chili peppers, onions, garlic, clove, peppercorns, cardamom seed, cumin seed, poppy seed, mace, cilantro, mint leaf, fresh lemon juice, plain yogurt, boneless chicken, salt, ghee, onion, tomatoes, basmati rice, long-grain rice, raisins, cashews, eggs\n",
      "Title: Biryani\n",
      "Ingredients: \n",
      "- 1 cup milk\n",
      "- 4 cups long-grain rice\n",
      "- 2 pinches salt\n",
      "- 2 cloves garlic\n",
      "- 8 hot green chili peppers\n",
      "- 1/4 tomatoes\n",
      "- 8 saffron\n",
      "- 1/2 tablespoon poppy seed\n",
      "- 1 lb onions\n",
      "- 1 cilantro\n",
      "- 1/4 mint leaf\n",
      "- 1/4 cashews\n",
      "- 1/2 lb onion\n",
      "- 1/4 cup basmati rice\n",
      "- 2 raisins\n",
      "- 3 clove\n",
      "-  peppercorns\n",
      "- 2 tablespoons cardamom seed\n",
      "- 1 teaspoon fresh lemon juice\n",
      "- 1 eggs\n",
      "- 8 ghee\n",
      "- 2 plain yogurt\n",
      "- 1/3 pinch cumin seed\n",
      "- 1/3 teaspoon mace\n",
      "- 1/3 boneless chicken\n",
      "Servings: 6\n",
      "Instructions: Soak saffron in warm milk for 5 minutes and puree in blender. Add chiles onions ginger garlic cloves peppercorns cardamom seeds cinnamon coriander and cumin seeds poppy seeds nutmeg mace cilantro or mint leaves and lemon juice. Blend into smooth paste. Put paste into large bowl add yogurt and mix well. Marinate chicken in yogurt mixture with salt covered for at least 2 - 6 hours in refrigerator. In skillet. heat oil over medium heat for 1 minute. Add ghee and 15 seconds later add onion and fry for about8 minutes. \n",
      "Reserve for garnish. In same skillet cook chicken with its marinade with tomatoes for about 10 minutes over medium heat uncovered. Remove chicken pieces from the sauce and set aside. Add rice to sauce bring to boil and cook covered over low heat for 15 minutes. Return chicken and add raisins cashews and almonds; mix well. Simmer covered for 5 minutes. Place chicken eggs and rice in large serving dish in such a way that yellow of the eggs the saffron-colored rice the nuts and the chicken make a colorful display. \n",
      "Add reserved onion as garnish.\n",
      "Cook time: 25 min \n",
      "Preparation time: 4 h \n",
      "Total time: 4 h 25 min <|endoftext|>\n",
      "<|startoftext|>Prompt: sugar, lemons, rind of, lemon, zest of, fresh water, fresh lemon juice\n",
      "Title: Best Lemonade\n",
      "Ingredients: \n",
      "- 1 1/2 cup sugar\n",
      "- 1 lemons\n",
      "-  lemon\n",
      "- 1 1/2 teaspoon fresh lemon juice\n",
      "-  rind of\n",
      "- 3/4 zest of\n",
      "Servings: 4\n",
      "Instructions: Into a 1 quart Jar with tight fitting lid put sugar and lemon peel or zest;  add 1 1/2 cups very hot water (not from tap!). With lid fitted firmly shake jar until sugar is dissolved. Add lemon juice. Refrigerate until chilled. To Serve: Into each 12-ounce glass over ice cubes pour 1/4 cup of the lemon syrup. Then add chilled club soda or if you prefer water. Stir to mix well.\n",
      "Cook time: 5 min \n",
      "Preparation time: 30 min \n",
      "Total time: 35 min <|endoftext|>\n",
      "<|startoftext|>Prompt: extra firm tofu, eggplant, zucchini, mushrooms, soy sauce, low sodium soy sauce, olive oil, maple syrup, honey, red wine vinegar, lemon juice, garlic cloves, mustard powder, black pepper\n",
      "Title: Carina's Tofu-Vegetable Kebabs\n",
      "Ingredients: \n",
      "- 12 eggplant\n",
      "- 1 tablespoon maple syrup\n",
      "- 2 tablespoons red wine vinegar\n",
      "- 1 garlic cloves\n",
      "- 10 g soy sauce\n",
      "- 1 cup honey\n",
      "- 3 cups mushrooms\n",
      "- 2 tablespoons black pepper\n",
      "- 2 tablespoons low sodium soy sauce\n",
      "- 2 tablespoons olive oil\n",
      "- 1 zucchini\n",
      "- 2 teaspoons lemon juice\n",
      "- 1/2 extra firm tofu\n",
      "- 1/4 tablespoon mustard powder\n",
      "Servings: 2\n",
      "Instructions: Drain the tofu carefully squeezing out excess water  and pat dry with paper towels. Cut tofu into one-inch squares. Set aside.  Cut  eggplant lengthwise in half then cut each half into approximately three strips. Cut strips crosswise into one-inch cubes. Slice zucchini into half-inch thick  slices. Cut red pepper in half removing stem and seeds and cut each half into  one-inch squares. Wipe mushrooms clean with a moist paper towel and remove  stems. Thread tofu and vegetables on to barbecue skewers in alternating color  combinations: For example first a piece of eggplant then a slice of tofu then zucchini then red pepper baby corn and mushrooms. \n",
      "Continue in this way until  all skewers are full. Make the marinade by putting all ingredients in a  blender and blend on high speed for about one minute until mixed. Alternatively put all ingredients in a glass jar cover tightly with the lid  and shake well until mixed. Lay the kebabs in a long shallow baking pan or on  a non-metal tray making sure they lie flat. Evenly pour the marinade over the  kebabs turning them once so that the tofu and vegetables are coated. Refrigerate the kebabs for three to eight hours occasionally spooning the  marinade over them. \n",
      "Broil or grill the kebabs at 450 F for 15-20 minutes or on the grill until the vegetables are browned. Suggestions  This meal can be served over cooked brown rice. Amounts can easily be doubled to make four servings.\n",
      "Cook time: 20 min \n",
      "Preparation time: 24 h \n",
      "Total time: 24 h 20 min <|endoftext|>\n",
      "<|startoftext|>Prompt: plain tomato juice, cabbage, onion, carrots, celery\n",
      "Title: Cabbage Soup\n",
      "Ingredients: \n",
      "- 46 cabbage\n",
      "- 4 lbs onion\n",
      "- 1 lb carrots\n",
      "- 2 stalks celery\n",
      "- 1 plain tomato juice\n",
      "Servings: 4\n",
      "Instructions: Mix everything together and bring to a boil. Reduce heat and simmer for 30 minutes (longer if you prefer your veggies to be soft). Refrigerate until cool. Serve chilled with sour cream.\n",
      "Cook time: 30 min \n",
      "Preparation time: 20 min \n",
      "Total time: 50 min <|endoftext|>\n",
      "<|startoftext|>Prompt: graham cracker crumbs, sugar, butter, sugar, cornstarch, salt, milk, vanilla extract, water, gelatin, rum, cream of tartar, sugar\n",
      "Title: Best Blackbottom Pie\n",
      "Ingredients: \n",
      "- 1 1/4 cup milk\n",
      "- 1/4 cup water\n",
      "- 6 cups sugar\n",
      "- 1/3 pinch salt\n",
      "- 1/4 teaspoon rum\n",
      "- 1/4 cup cream of tartar\n",
      "- 2 tablespoons cornstarch\n",
      "- 3 gelatin\n",
      "- 1 teaspoon vanilla extract\n",
      "- 1 ounce butter\n",
      "- 1/4 cup graham cracker crumbs\n",
      "Servings: 8\n",
      "Instructions: Graham Cracker Crust: In small bowl combine graham cracker crumbs sugar   and butter.  Press evenly on bottom and sides of 9-inch pie plate. Chill   until firm (about 1 hour). Chocolate Layer: In medium saucepan combine sugar cornstarch and salt.   Gradually stir in milk.  Cook over medium heat stirring constantly until   mixture boils.  Remove from heat. In small bowl beat egg yolks. Gradually   stir in small amount of hot mixture; return to saucepan. Cook over low   heat stirring constantly for 2 minutes. Remove from heat. \n",
      "Remove 1-1/2   cups custard to medium bowl; add  semi-sweet chocolate   morsels and vanilla extract. Stir until morsels are melted and mixture is   smooth. Pour into prepared Graham Cracker Crust; chill until set (about 30   minutes). While Chocolate Layer is chilling prepare Vanilla Layer. Vanilla Layer: In large bowl combine cold water and gelatin; let stand 5   minutes.  Add remaining warm custard; stir until gelatin dissolves.  Cool 15   minutes.  Stir in rum; beat with wire whisk until smooth. Set aside. \n",
      "In   1-1/2 quart bowl combine egg whites and cream of tartar; beat until foamy.  Gradually add sugar; beat until stiff peaks form.  Fold egg whites into   custard; pour over chocolate layer. Chill until set (about 2 hours). Garnish with whipped cream and chocolate shavings if desired. Makes one   9-inch pie.\n",
      "Cook time: 2 h \n",
      "Preparation time: 20 min \n",
      "Total time: 2 h 20 min <|endoftext|>\n",
      "<|startoftext|>Prompt: chicken, butter, flour, milk, celery, button mushrooms, green pepper, canned pimiento, salt, black pepper, Worcestershire sauce, parsley\n",
      "Title: Warm Chicken A La King\n",
      "Ingredients: \n",
      "- 12 g milk\n",
      "- 2 cups button mushrooms\n",
      "- 3 green pepper\n",
      "- 450 g parsley\n",
      "- 1 tablespoon black pepper\n",
      "- 2 canned pimiento\n",
      "- 1/4 tablespoon Worcestershire sauce\n",
      "- 1 cup flour\n",
      "-  salt\n",
      "- chicken\n",
      "- 2 ounces butter\n",
      "- 2 stalks celery\n",
      "Servings: 2\n",
      "Instructions: Melt 1 1/2 ozs butter add the flour and cook for 2 to 3 minutes stirring. Gradually add milk and cook stirring until thick and smooth. Melt the  remaining butter and saute sliced celery button mushrooms and chopped pepper  until soft but not coloured. Add celery mushrooms pepper chicken and  pimiento to the sauce and heat through. Season to taste.  Combine the egg  yolks double cream and Worcestershire sauce. Add to the chicken mixture and  heat through. Transfer to a serving dish and sprinkle with chopped parsley.\n",
      "Cook time: 3 min \n",
      "Preparation time: 35 min \n",
      "Total time: 38 min <|endoftext|>\n",
      "<|startoftext|>Prompt: sugar, margarine, egg, flour, salt, buttermilk, graham cracker crumbs, margarine\n",
      "Title: Buttermilk Pie With Gingersnap Crumb Crust\n",
      "Ingredients: \n",
      "- 3/4 cup sugar\n",
      "- 1 ounce margarine\n",
      "- 1 cup flour\n",
      "- 2 pinches salt\n",
      "- 3 cups graham cracker crumbs\n",
      "- 1/4 egg\n",
      "- 1 cup buttermilk\n",
      "Servings: 8\n",
      "Instructions: Preheat oven to 350°F. Make pie crust using 8 inch pie pan do not bake. Mix sugar and margarine in medium bowl until blended; beat in egg whites and egg. Stir in flour salt and buttermilk until well blended. Pour filling into prepared crust bake 40 minutes or until sharp knife inserted near center comes out clean. Sprinkle with nutmeg and serve warm or chilled. Combine graham crumbs gingersnap crumbs and margarine in 8 or 9 inch pie pan pat mixture evenly on bottom and side of pan. \n",
      "Bake 8 to 10 minutes or until edge of crust is lightly browned. Cool on wire rack.\n",
      "Cook time: 50 min \n",
      "Preparation time: 30 min \n",
      "Total time: 1 h 20 min <|endoftext|>\n",
      "<|startoftext|>Prompt: rice vinegar, haeo\n",
      "Title: A Jad - Cucumber Pickle\n",
      "Ingredients: \n",
      "- 1/2 tablespoon rice vinegar\n",
      "- 5 haeo\n",
      "Servings: 1 cup\n",
      "Instructions: Slice the cucumber in four lengthwise then slice the pieces to segments about an eighth of an inch thick. Slice the tops of the chilies (green ones can be used if red are not available but Thais like the color contrast) tap out any loose seeds and discard then slice the chilies across into thin rounds. Slice the shallots and water chestnuts. Combine and serve. This will keep 2 or 3 weeks in a refrigerator.\n",
      "Preparation time: 25 min \n",
      "Total time: 25 min <|endoftext|>\n",
      "<|startoftext|>Prompt: butter, brown sugar, granulated sugar, vanilla extract, flour, pecan halves\n",
      "Title: Butter Pecan Cookies\n",
      "Ingredients: \n",
      "- 3/4 cup granulated sugar\n",
      "- 1/2 ounce butter\n",
      "- 1 cup brown sugar\n",
      "- 1 cup flour\n",
      "- 1 pecan halves\n",
      "- 2 teaspoons vanilla extract\n",
      "Servings: 84 cookies\n",
      "Instructions: Preheat oven to 350 degrees. Cream butter in large mixing bowl. Gradually add brown sugar and granulated sugar. Cream well. Add unbeaten egg yolk and vanilla and beat well. Blend in sifted flour to form a stiff dough. Shape dough into small balls. Place on greased cookie sheet. Flatten cookies with bottom of glass dipped in sugar. Bake at 350 degrees for 7-9 minutes till golden brown (do not overbrown.) Cool before frosting. Garnish with pecan halves.\n",
      "Cook time: 9 min \n",
      "Preparation time: 55 min \n",
      "Total time: 1 h 4 min <|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "for recipe in recipes4[:10]:\n",
    "    print(recipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5be71112-9716-49a9-b319-ed2a637634b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_list = recipes1 + recipes2 + recipes3 + recipes4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84720437-7c4e-4cd3-b45c-4f0b2c1d0972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39441\n",
      "18145\n",
      "55781\n",
      "487622\n"
     ]
    }
   ],
   "source": [
    "print(len(recipes1))\n",
    "print(len(recipes2))\n",
    "print(len(recipes3))\n",
    "print(len(recipes4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0557a17f-6925-4914-a32e-b7b648d20e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train data:  480791\n",
      "Number of test data:  966\n"
     ]
    }
   ],
   "source": [
    "random.shuffle(recipe_list)\n",
    "train_list, test_list = recipe_list[:int(.8*len(recipe_list))], recipe_list[int(.8*len(recipe_list))]\n",
    "print('Number of train data: ', len(train_list))\n",
    "print('Number of test data: ', len(test_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db555e3c-52d2-4410-a0de-008181d7a11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('distilbert/distilgpt2', bos_token='<|startoftext|>', eos_token='<|endoftext|>', pad_token='<|pad|>')\n",
    "configuration = GPT2Config.from_pretrained('distilbert/distilgpt2', output_hidden_states=False)\n",
    "\n",
    "# instantiate the model\n",
    "model = GPT2LMHeadModel.from_pretrained(\"distilbert/distilgpt2\", config=configuration)\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a3cdbf0-f7ed-4ccc-8999-061c9530d130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50259, 768)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('recipes_generator/model/recipes_generation_mode', bos_token='<|startoftext|>', eos_token='<|endoftext|>', pad_token='<|pad|>')\n",
    "configuration = GPT2Config.from_pretrained('recipes_generator/model/recipes_generation_mode', output_hidden_states=False)\n",
    "\n",
    "# instantiate the model\n",
    "model = GPT2LMHeadModel.from_pretrained(\"recipes_generator/model/recipes_generation_mode\", config=configuration)\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b38a44b9-b940-4d8f-a7ce-e2bbb49fdb99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "432,711 training samples\n",
      "48,080 validation samples\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, random_split, RandomSampler, SequentialSampler\n",
    "\n",
    "dataset = RecipeDataset(train_list, tokenizer)\n",
    "\n",
    "# Split into training and validation sets\n",
    "train_size = int(0.9 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "del dataset\n",
    "\n",
    "print('{:>5,} training samples'.format(train_size))\n",
    "print('{:>5,} validation samples'.format(val_size))\n",
    "\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14fa8d5-f2da-4d9b-97a2-696800715e7e",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27379559-d557-4390-93c8-c1ef414c7049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently using device type:  cuda\n"
     ]
    }
   ],
   "source": [
    "# Finetune\n",
    "import torch\n",
    "import random\n",
    "\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "\n",
    "# some parameters I cooked up that work reasonably well\n",
    "\n",
    "epochs = 2\n",
    "\n",
    "# this produces sample output every 100 steps\n",
    "sample_every = 1000\n",
    "# I save the model every 5000 step\n",
    "save_every = 5000\n",
    "# save the model to this file name\n",
    "save_file = 'recipes_generator/model/recipes_generation_model'\n",
    "\n",
    "\n",
    "\n",
    "training_stats = []\n",
    "print(\"Currently using device type: \", device)\n",
    "\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fecd9372-70ac-46db-9725-211b74c2a374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of steps:  108178\n",
      "Currently using device type:  cuda\n",
      "\n",
      "======== Epoch 1 / 2 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 54088, Loss: 0.5402792096138: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 54089/54089 [9:47:50<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss: 0.55\n",
      "  Perplexity: 1.73\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.4237533509731293: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6010/6010 [21:49<00:00,  4.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation Loss: 0.48\n",
      "  Validation perplexity: 1.61\n",
      "\n",
      "======== Epoch 2 / 2 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 0, Loss: 0.6113799810409546:   0%|                                                                                                                                                              | 1/54089 [00:01<19:10:02,  1.28s/it]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1.05 GiB. GPU ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Fine-tune the GPT-2 model on the recipe dataset\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrecipes_generator\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrecipe_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_model\n\u001b[0;32m----> 3\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(history)\n",
      "File \u001b[0;32m~/Documents/documenti uni/sistemi digitali/projects/SmartFridge/AIChefModel/recipes_generator/model/recipe_model.py:263\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_dataset, val_dataset, epochs, batch_size, device, sample_every, save_every, save_file, learning_rate, warmup_steps, epsilon)\u001b[0m\n\u001b[1;32m    259\u001b[0m b_masks \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    261\u001b[0m model\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 263\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m                \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mb_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m                \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mb_masks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m                \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    269\u001b[0m loss \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    270\u001b[0m \u001b[38;5;66;03m##call the method above and add student&teacher model\u001b[39;00m\n",
      "File \u001b[0;32m~/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/venv/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py:1107\u001b[0m, in \u001b[0;36mGPT2LMHeadModel.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1105\u001b[0m     \u001b[38;5;66;03m# Flatten the tokens\u001b[39;00m\n\u001b[1;32m   1106\u001b[0m     loss_fct \u001b[38;5;241m=\u001b[39m CrossEntropyLoss()\n\u001b[0;32m-> 1107\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshift_logits\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshift_logits\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshift_labels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict:\n\u001b[1;32m   1110\u001b[0m     output \u001b[38;5;241m=\u001b[39m (lm_logits,) \u001b[38;5;241m+\u001b[39m transformer_outputs[\u001b[38;5;241m1\u001b[39m:]\n",
      "File \u001b[0;32m~/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/venv/lib/python3.11/site-packages/torch/nn/modules/loss.py:1185\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m-> 1185\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1186\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1187\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv/lib/python3.11/site-packages/torch/nn/functional.py:3086\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3084\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3085\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3086\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1.05 GiB. GPU "
     ]
    }
   ],
   "source": [
    "# Fine-tune the GPT-2 model on the recipe dataset\n",
    "from recipes_generator.model.recipe_model import train_model\n",
    "history = train_model(model, train_dataset, val_dataset, epochs, batch_size, device, save_file=save_file)\n",
    "print(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3a4c1b3-dca6-4fd5-bedc-0ce8955e28c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('recipes_generator/model/recipes_generation_model/tokenizer_config.json',\n",
       " 'recipes_generator/model/recipes_generation_model/special_tokens_map.json',\n",
       " 'recipes_generator/model/recipes_generation_model/vocab.json',\n",
       " 'recipes_generator/model/recipes_generation_model/merges.txt',\n",
       " 'recipes_generator/model/recipes_generation_model/added_tokens.json')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(save_file)\n",
    "tokenizer.save_pretrained(save_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e3bb7a-7ae9-499b-b187-ce6adc2936e4",
   "metadata": {},
   "source": [
    "# Training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12a4cfdb-e831-42c0-b29d-4c4798309d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(50259, 768)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"recipes_generator/model/recipes_generation_model\", bos_token='<|startoftext|>', eos_token='<|endoftext|>', pad_token='<|pad|>')\n",
    "# I'm not really doing anything with the config buheret\n",
    "configuration = GPT2Config.from_pretrained(save_file, output_hidden_states=False)\n",
    "\n",
    "# instantiate the model\n",
    "model = GPT2LMHeadModel.from_pretrained(save_file, config=configuration)\n",
    "\n",
    "# this step is necessary because I've added some tokens (bos_token, etc) to the embeddings\n",
    "# otherwise the tokenizer and model tensors won't match up\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c454b99-c1ba-440d-adb1-f0092ea59af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                               | 0/121 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1.15 GiB. GPU ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m RecipeDataset(test_list, tokenizer, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m768\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTesting...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m test_loss, test_perplexity \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m test_eval_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_perplexity\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      8\u001b[0m test_eval_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_loss\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m test_loss\n",
      "File \u001b[0;32m~/Documents/documenti uni/sistemi digitali/projects/SmartFridge/AIChefModel/recipes_generator/model/recipe_model.py:388\u001b[0m, in \u001b[0;36mevaluate_model\u001b[0;34m(model, test_dataset, batch_size, device)\u001b[0m\n\u001b[1;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "File \u001b[0;32m~/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/venv/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py:1096\u001b[0m, in \u001b[0;36mGPT2LMHeadModel.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1093\u001b[0m     torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mset_device(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer\u001b[38;5;241m.\u001b[39mfirst_device)\n\u001b[1;32m   1094\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m-> 1096\u001b[0m lm_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlm_head\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1098\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;66;03m# move labels to correct device to enable model parallelism\u001b[39;00m\n",
      "File \u001b[0;32m~/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1.15 GiB. GPU "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from recipes_generator.model.recipe_model import evaluate_model\n",
    "test_dataset = RecipeDataset(test_list, tokenizer, max_length=768)\n",
    "print('Testing...')\n",
    "test_loss, test_perplexity = evaluate_model(model, test_dataset, batch_size, device)\n",
    "test_eval_df = pd.DataFrame(columns = [\"test_loss\", \"test_perplexity\"])\n",
    "test_eval_df['test_loss'] = test_loss\n",
    "test_eval_df['test_perplexity'] = test_perplexity\n",
    "test_eval_df.to_csv(\"recipes_generator/model/recipes_generation_model/test_eval_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b15979-b2ca-4657-904e-c8a1c3a0ef2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_eval_df = pd.DataFrame(columns = [\"epoch\", \"training loss\", \"validation loss\", \"train perplexity\", \"validation perplexity\"])\n",
    "train_loss = []\n",
    "train_perp = []\n",
    "valid_loss = []\n",
    "valid_perp = []\n",
    "for epoch in history:\n",
    "    train_loss.append(epoch['Training Loss'])\n",
    "    train_perp.append(epoch['Training Perplexity'])\n",
    "    valid_loss.append(epoch['Valid. Loss'])\n",
    "    valid_perp.append(epoch['Valid. Perplexity'])\n",
    "\n",
    "training_eval_df['epoch'] = [x for x in range(len(training_stats))]\n",
    "training_eval_df['training loss'] = train_loss\n",
    "training_eval_df['validation loss'] = valid_loss\n",
    "training_eval_df['train perplexity'] = train_perp\n",
    "training_eval_df['validation perplexity'] = valid_perp\n",
    "\n",
    "training_eval_df.to_csv(\"recipes_generator/model/recipes_generation_model/train_eval.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6a1d13-d781-4618-a7c6-aa118724af5a",
   "metadata": {},
   "source": [
    "# Examples of generated recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5afe7d8-de8c-46ff-b728-54bc5d71c000",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_loaded = GPT2LMHeadModel.from_pretrained(\"model\", config=configuration, ignore_mismatched_sizes=True)\n",
    "def infer(prompt, model, tokenizer):\n",
    "    input = f\"<|startoftext|>Prompt: {prompt.strip()}\"\n",
    "    input = tokenizer(input, return_tensors=\"pt\")\n",
    "    input_ids      = input[\"input_ids\"]\n",
    "    attention_mask = input[\"attention_mask\"]\n",
    "\n",
    "    output = model.generate(input_ids.to(device),\n",
    "                            attention_mask=attention_mask.to(device),\n",
    "                            max_new_tokens=200,\n",
    "                            num_beams=5, \n",
    "                            no_repeat_ngram_size=2, \n",
    "                            max_length = 600,\n",
    "                            num_return_sequences=1,\n",
    "                            eos_token_id=tokenizer.eos_token_id,\n",
    "                            do_sample = True, top_k = 100, top_p = 0.85)\n",
    "    output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d1670bb-8e07-41de-85de-ed5512a8cf16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=200) and `max_length`(=600) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=200) and `max_length`(=600) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: chocolate,flour,sugar, eggs, vanilla essence, self-raising flour, cocoa powder\n",
      "Title: Chocolate Mousse Cake\n",
      "Ingredients: 200 chocolate\n",
      "Servings: 1\n",
      "Instructions: Preheat oven to 180°C. Grease and line a 20cm springform cake tin. Melt chocolate in a heatproof bowl over a pan of simmering water. Remove from heat and stir in sugar until dissolved. Add eggs one at a time beating well after each addition. Stir in vanilla. Fold in sifted flour and cocoa. Pour into prepared tin and bake for 30-35 minutes or until a skewer inserted into the centre comes out clean. Cool in the tin for 10 minutes then remove to a wire rack to cool completely. To make the mousse cream the cream until soft peaks form. Gradually add the sugar and continue to beat until stiff and glossy. \n",
      "Spread over the top of the cake.\n",
      "Cook time: PT35M\n",
      "Preparation time : PT15H\n",
      "Total time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=200) and `max_length`(=600) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: chicken, flour, lemon, parmesan cheese, butter, margarine\n",
      "Title: Chicken Parmesan\n",
      "Ingredients: 1 chicken\n",
      "Servings: 4\n",
      "Instructions: Preheat oven to 350°F. Wash chicken and pat dry with paper towels. Sprinkle with salt and pepper. Place chicken in a shallow baking dish. In a small bowl combine the flour and the lemon juice. Dredge chicken pieces in flour mixture. Melt the butter and pour over chicken. Bake uncovered for 45 minutes or until chicken is tender.\n",
      "Cook time: PT45M\n",
      "Preparation time : PT10M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=200) and `max_length`(=600) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: courgette, aubergine,flour,lemon, milk, eggs, parmesan cheese, butter, margarine, olive oil, onion, garlic clove, celery, carrot, parsnip, green beans, zucchini, tomatoes, eggplant, flour, salt, pepper, nutmeg, cayenne pepper\n",
      "Title: Vegetable Frittata\n",
      "Ingredients: 1/2 cour Vegie,  1 auornine\n",
      "Servings: 4\n",
      "Instructions: Preheat the oven to 180C/350F/gas mark 4. Grease an ovenproof dish with butter and line with baking paper. Heat the oil in a frying pan and add the onion and garlic and cook for a few minutes until soft but not coloured. Add the veg and saute for another minute or two. Pour in the stock and bring to the boil. Reduce the heat and simmer for 10-15 minutes or until all the liquid has evaporated. Whisk the egg yolks with a little of the milk and\n",
      "Prompt: courgette, pepper, flour, mid-seasoned cheese, butter, margarine\n",
      "Title: Courgettes Au Gratin\n",
      "Ingredients: 1/2 courpe,  pepper\n",
      "Servings: 4\n",
      "Instructions: Preheat oven to 180°C. Grease a shallow 2 litre baking dish with the butter. Arrange courgtes in a single layer in the dish. Sprinkle with pepper and sprinkle with cheese. Pour cream over all. Cover with foil and bake for 30 minutes. Uncover and cook for a further 10 minutes or until the top is golden and bubbling. Serve hot.\n",
      "Cook time: PT40M\n",
      "Preparation time : PT10M\n"
     ]
    }
   ],
   "source": [
    "prompts = ['chocolate,flour,sugar', 'chicken, flour, lemon, parmesan cheese', 'courgette, aubergine,flour,lemon', 'courgette, pepper, flour, mid-seasoned cheese']\n",
    "generated_recipes = []\n",
    "for p in prompts:    \n",
    "    recipe = infer(p, model, tokenizer)\n",
    "    print(recipe)\n",
    "    generated_recipes.append(recipe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43c3bb38-a1f6-4052-852d-dcf6e0ab7a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=200) and `max_length`(=600) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=200) and `max_length`(=600) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: chocolate,flour,sugar, eggs, vanilla essence, self raising flour, cocoa powder\n",
      "Title: Chocolate Mousse Cake\n",
      "Ingredients: 200 chocolate\n",
      "Servings: 1\n",
      "Instructions: Preheat oven to 180°C. Grease and line the base of a 20cm springform cake tin. Melt the chocolate in a heatproof bowl over a pan of simmering water. Remove from the heat and stir in the sugar. Add the egg yolks one at a time beating well after each addition. Beat the cream until soft peaks form. Fold the melted chocolate into the whipped cream. Sift the self-raising flour and cocoa into a bowl and fold in gently. In a clean bowl beat egg whites until stiff and glossy. Gently fold the meringue into chocolate mixture. Pour the mixture into prepared tin and bake for 30-35 minutes or until a skewer comes out clean. \n",
      "Leave to cool for 10 minutes then turn out onto a wire rack and cool completely.\n",
      "Cook time:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=200) and `max_length`(=600) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: chicken, flour, lemon, parmesan cheese, butter, margarine\n",
      "Title: Chicken Parmesan\n",
      "Ingredients: 1 chicken\n",
      "Servings: 4\n",
      "Instructions: Preheat oven to 350°F. Wash chicken and pat dry. Sprinkle with salt and pepper. Melt butter in baking dish. Place chicken in dish and sprinkle with cheese. Bake for 30 minutes or until chicken is done.\n",
      "Cook time: PT30M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=200) and `max_length`(=600) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: courgette, aubergine,flour,lemon, onion, garlic cloves, cumin seed, mustard seeds, garam masala, turmeric powder, salt, tomatoes, tomato puree, water, green chilies, coriander leaves\n",
      "Title: Roasted Vegetable Curry\n",
      "Ingredients: 1/2 - 3/4 cournut,  1 -2 Auberginine\n",
      "Servings: 4\n",
      "Instructions: Preheat oven to 180°C. Place all the vegetables in a large roasting tin. Sprinkle with salt and pepper. Roast for 30 minutes. Remove from the oven and set aside. In a frying pan heat the oil and fry the onion until soft. Add the garlic and saute for a further 30 seconds. Stir in the spices and cook for 1 minute. Return the veg to the pan and add the pureed tomatoes and water. Bring to a boil and then reduce the heat and simmer for 10-15 minutes or until the veggies are tender.\n",
      "Cook time: PT45M\n",
      "Prompt: courgette, pepper, flour, mid-seasoned cheese, butter, margarine\n",
      "Title: Courgettes Au Gratin\n",
      "Ingredients: 1/2 courpe,  1 pepper\n",
      "Servings: 4\n",
      "Instructions: Preheat oven to 180°C. Grease a shallow 1.5 litre casserole dish. Sprinkle with half the cheese. Repeat layers. Melt the butter in a frying pan and fry the vegetables for 5 minutes or until soft. Pour into the dish and sprinkle with the remaining cheese and breadcrumbs. Bake for 30 minutes.\n",
      "Cook time: PT30M\n",
      "Preparation time : PT10M\n"
     ]
    }
   ],
   "source": [
    "prompts = ['chocolate,flour,sugar', 'chicken, flour, lemon, parmesan cheese', 'courgette, aubergine,flour,lemon', 'courgette, pepper, flour, mid-seasoned cheese']\n",
    "model_loaded = GPT2LMHeadModel.from_pretrained(save_file, ignore_mismatched_sizes=True).to(device)\n",
    "tokenizer_loaded = GPT2TokenizerFast.from_pretrained(\"tokenizer\")\n",
    "generated_recipes_from_loaded = []\n",
    "for p in prompts:    \n",
    "    recipe = infer(p, model_loaded, tokenizer_loaded)\n",
    "    print(recipe)\n",
    "    generated_recipes_from_loaded.append(recipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94f63a5d-889b-4881-a033-5429ee46cc1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpu4hogbn7/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpu4hogbn7/assets\n",
      "W0000 00:00:1714894416.753534  101219 tf_tfl_flatbuffer_helpers.cc:392] Ignored output_format.\n",
      "W0000 00:00:1714894416.753551  101219 tf_tfl_flatbuffer_helpers.cc:395] Ignored drop_control_dependency.\n",
      "2024-05-05 09:33:36.753682: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpu4hogbn7\n",
      "2024-05-05 09:33:36.759756: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2024-05-05 09:33:36.759767: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /tmp/tmpu4hogbn7\n",
      "2024-05-05 09:33:36.798794: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2024-05-05 09:33:36.946764: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /tmp/tmpu4hogbn7\n",
      "2024-05-05 09:33:36.994994: I tensorflow/cc/saved_model/loader.cc:462] SavedModel load for tags { serve }; Status: success: OK. Took 241315 microseconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "163972456"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import TFGPT2LMHeadModel, GPT2Config, GPT2Tokenizer\n",
    "config = GPT2Config.from_pretrained(\"recipes_generation_model\")\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"recipes_generation_model\")\n",
    "model_loaded = TFGPT2LMHeadModel.from_pretrained(\"recipes_generation_model\", ignore_mismatched_sizes=True, config=config)\n",
    "\n",
    "#model_loaded.build((1, 768))\n",
    "inputs = tokenizer(\"<|startoftext|>Prompt:aubergines,courgettes,eggs\", return_tensors=\"tf\")\n",
    "outputs = model_loaded(inputs)\n",
    "print(model_loaded.inputs)\n",
    "print(model_loaded.outputs)\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_loaded)\n",
    "\n",
    "# For FP16 quantization:\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_types = [tf.float16]\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "open(\"recipes_generator.tflite\", \"wb\").write(tflite_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
